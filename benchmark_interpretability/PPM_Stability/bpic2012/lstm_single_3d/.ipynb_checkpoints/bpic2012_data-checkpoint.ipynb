{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "import sys\n",
    "#PATH = '/content/drive/My Drive/PPM_Stability/'\n",
    "#PATH = \"C:/Users/velmurug/Documents/Stability Experiments/benchmark_interpretability/PPM_Stability/\"\n",
    "#PATH = \"C:/Users/Mythreyi/Documents/GitHub/Stability-Experiments/benchmark_interpretability/PPM_Stability/\"\n",
    "#PATH = \"C:/Users/mythr/Documents/GitHub/Stability-Experiments/benchmark_interpretability/PPM_Stability/\"\n",
    "PATH = \"C:/Users/n9455647/Documents/GitHub/Stability-Experiments/benchmark_interpretability/PPM_Stability/\"\n",
    "sys.path.append(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DatasetManager import DatasetManager\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from sys import argv\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "lime_pal = sns.diverging_palette(100, 200, s=150)#, as_cmap=True)\n",
    "shap_pal = sns.diverging_palette(0, 240, s=150)#, as_cmap=True)\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "#sns.axes_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bpic2012_accepted']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ref = \"bpic2012\"\n",
    "params_dir = PATH + \"params\"\n",
    "results_dir = \"results\"\n",
    "bucket_method = \"single\"\n",
    "cls_encoding = \"3d\"\n",
    "cls_method = \"lstm\"\n",
    "\n",
    "gap = 1\n",
    "n_iter = 1\n",
    "\n",
    "method_name = \"%s_%s\"%(bucket_method, cls_encoding)\n",
    "\n",
    "generate_samples = False\n",
    "generate_lime = True\n",
    "generate_kernel_shap = False\n",
    "generate_model_shap = True\n",
    "\n",
    "sample_size = 2\n",
    "exp_iter = 10\n",
    "max_feat = 10\n",
    "max_prefix = 25\n",
    "\n",
    "dataset_ref_to_datasets = {\n",
    "    #\"bpic2011\": [\"bpic2011_f%s\"%formula for formula in range(1,5)],\n",
    "    \"bpic2015\": [\"bpic2015_%s_f2\"%(municipality) for municipality in range(5,6)],\n",
    "    \"bpic2017\" : [\"bpic2017_accepted\"],\n",
    "    \"bpic2012\" : [\"bpic2012_accepted\"],\n",
    "    #\"insurance\": [\"insurance_activity\", \"insurance_followup\"],\n",
    "    \"sepsis_cases\": [\"sepsis_cases_1\"],# \"sepsis_cases_2\", \"sepsis_cases_4\"]\n",
    "    \"production\" : [\"production\"]\n",
    "}\n",
    "\n",
    "datasets = [dataset_ref] if dataset_ref not in dataset_ref_to_datasets else dataset_ref_to_datasets[dataset_ref]\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/n9455647/Documents/GitHub/Stability-Experiments/benchmark_interpretability/PPM_Stability/bpic2012/lstm_single_3d/sep_timing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b5911ebef4f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mall_timing_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%s/%s_%s/all_timing.csv\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdataset_ref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0msep_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msep_timing_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mall_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_timing_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/n9455647/Documents/GitHub/Stability-Experiments/benchmark_interpretability/PPM_Stability/bpic2012/lstm_single_3d/sep_timing.csv'"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    sep_timing_path = os.path.join(PATH, \"%s/%s_%s/sep_timing.csv\" % (dataset_ref, cls_method, method_name))\n",
    "    all_timing_path = os.path.join(PATH, \"%s/%s_%s/all_timing.csv\" % (dataset_ref, cls_method, method_name))\n",
    "    \n",
    "    sep_data = pd.read_csv(sep_timing_path)\n",
    "    all_data = pd.read_csv(all_timing_path)\n",
    "    \n",
    "    time_plot = sns.scatterplot(x = all_data['Prefix Length'], y = all_data['Running Time'], hue = all_data['Explainer'], size = all_data['Feature Vector Length'])\n",
    "    plt.xlabel(\"Prefix Length\")\n",
    "    plt.ylabel(\"Running Time (Seconds)\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,1.1, 0.1))\n",
    "    #plt.ylim(0,1.1)\n",
    "    plt.title(\"BPIC 2012: Running Time \\n LSTM - 3D encoding\")\n",
    "    plot = time_plot.get_figure()\n",
    "    plot.savefig(\"figures/timing.png\", bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_caseID = []\n",
    "all_lengths = []\n",
    "all_proba = []\n",
    "all_lime_stab = []\n",
    "all_shap_stab = []\n",
    "\n",
    "for dataset_name in datasets:\n",
    "\n",
    "    dataset_manager = DatasetManager(dataset_name)\n",
    "\n",
    "    for ii in range(n_iter):\n",
    "        if cls_method == \"lstm\":\n",
    "            num_buckets = 1\n",
    "        else:\n",
    "            num_buckets = len([name for name in os.listdir(os.path.join(PATH,'%s/%s_%s/models'% (dataset_ref, cls_method, method_name)))])\n",
    "        \n",
    "        #if num_buckets < max_prefix:\n",
    "        #    max_prefix = num_buckets\n",
    "            \n",
    "        #buckets = range(0, max_prefix, gap)\n",
    "\n",
    "        for bucket in range(num_buckets):\n",
    "            if cls_method == \"lstm\":\n",
    "                bucketID = \"all\"\n",
    "            else:\n",
    "                bucketID = bucket+1\n",
    "            print ('Bucket', bucketID)\n",
    "\n",
    "             #import everything needed to sort and predict\n",
    "            if cls_method == \"lstm\":\n",
    "                cls_path = os.path.join(PATH, \"%s/%s_%s/cls/pred_cls.h5\" % (dataset_ref, cls_method, method_name))\n",
    "                #pred_cls = load_model(cls_path)\n",
    "            else:\n",
    "                pipeline_path = os.path.join(PATH, \"%s/%s_%s/pipelines/pipeline_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "                feat_comb_path = os.path.join(PATH, \"%s/%s_%s/bucketers_and_encoders/feature_combiner_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "                bucketer_path = os.path.join(PATH, \"%s/%s_%s/bucketers_and_encoders/bucketer_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "                cls_path = os.path.join(PATH, \"%s/%s_%s/models/cls_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "\n",
    "                predictor = joblib.load(pipeline_path)\n",
    "                cls = joblib.load(cls_path)\n",
    "                feature_combiner = joblib.load(feat_comb_path)\n",
    "                bucketer = joblib.load(bucketer_path)\n",
    "\n",
    "            #import previously identified samples\n",
    "            tn_path = os.path.join(PATH, \"%s/%s_%s/samples/true_neg_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            tp_path = os.path.join(PATH, \"%s/%s_%s/samples/true_pos_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            fn_path = os.path.join(PATH, \"%s/%s_%s/samples/false_neg_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            fp_path = os.path.join(PATH, \"%s/%s_%s/samples/false_pos_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "\n",
    "            sample_instances = []\n",
    "\n",
    "            with open (tn_path, 'rb') as f:\n",
    "                tn_list = pickle.load(f)\n",
    "            with open (tp_path, 'rb') as f:\n",
    "                tp_list = pickle.load(f)\n",
    "            with open (fn_path, 'rb') as f:\n",
    "                fn_list = pickle.load(f)\n",
    "            with open (fp_path, 'rb') as f:\n",
    "                fp_list = pickle.load(f)\n",
    "            \n",
    "            print(len(tn_list))\n",
    "            print(len(tp_list))\n",
    "            print(len(fn_list))\n",
    "            print(len(fp_list))\n",
    "\n",
    "            #save results to a list\n",
    "            sample_instances.append(tn_list)\n",
    "            sample_instances.append(tp_list)\n",
    "            sample_instances.append(fn_list)\n",
    "            sample_instances.append(fp_list)\n",
    "            \n",
    "            type_list = [\"True Negatives\", \"True Positives\", \"False Negatives\", \"False Positives\"]\n",
    "            \n",
    "            for i in range(len(sample_instances)):\n",
    "                print (type_list[i])\n",
    "                data = pd.DataFrame.from_records(sample_instances[i])\n",
    "                \n",
    "                case_id = pd.Series(data['caseID'])\n",
    "                nr_events = pd.Series(data['nr_events'])\n",
    "                proba = pd.Series(data['proba'])\n",
    "                lime_stability = pd.Series(data['lime_stability'])\n",
    "                tree_shap_stability = pd.Series(data['tree_shap_stability'])\n",
    "                \n",
    "                all_caseID.extend(case_id)\n",
    "                all_lengths.extend(nr_events)\n",
    "                all_proba.extend(proba)\n",
    "                all_lime_stab.extend(lime_stability)\n",
    "                all_shap_stab.extend(tree_shap_stability)\n",
    "                \n",
    "                print(\"Average LIME Stability:\", statistics.mean(lime_stability))\n",
    "                print(\"Average SHAP Stability:\", statistics.mean(tree_shap_stability))\n",
    "                \n",
    "                #fig, ax = plt.subplots()\n",
    "                #ax.plot(nr_events, lime_stability, 'bo', label = \"LIME\")\n",
    "                #ax.plot(nr_events, tree_shap_stability, 'ro', label = \"Tree SHAP\")\n",
    "                #ax.set_xlabel(\"Prefix Length\")\n",
    "                #ax.set_ylabel(\"Stability\")\n",
    "                #ax.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,1, 0.1))\n",
    "                #plt.title(\"Prefix length and stability by index - \"+type_list[i])\n",
    "                #plt.show()\n",
    "                \n",
    "                #fig2, ax2 = plt.subplots()\n",
    "                #ax2.plot(proba, lime_stability, 'bo', label = \"LIME\")\n",
    "                #ax2.plot(proba, tree_shap_stability, 'ro', label = \"Tree SHAP\")\n",
    "                #ax2.set_xlabel(\"Prediction Probability\")\n",
    "                #ax2.set_ylabel(\"Stability\")\n",
    "                #ax2.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,1, 0.1))\n",
    "                #plt.title(\"Prediction probability and stability by index - \"+type_list[i])\n",
    "                #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(all_lengths)\n",
    "bins = np.arange(0, max_len+10, 5)\n",
    "labels = []\n",
    "for i in range(len(bins)-1):\n",
    "    start = str(int(bins[i]+1))\n",
    "    end = str(int(bins[i+1]))\n",
    "    label = start+\"-\"+end+\" prefixes\"\n",
    "    labels.append(label)\n",
    "\n",
    "hue_lens = []\n",
    "for length in all_lengths:\n",
    "    cur_bin = 0\n",
    "    while length >= bins[cur_bin+1]:\n",
    "        cur_bin += 1\n",
    "    hue_lens.append(labels[cur_bin])\n",
    "#hue_lens\n",
    "\n",
    "sorted_lists = sorted(zip(all_proba, all_lime_stab, all_shap_stab, all_lengths, hue_lens), key=lambda x: x[3])\n",
    "all_proba, all_lime_stab, all_shap_stab, all_lengths, hue_lens = [[x[i] for x in sorted_lists] for i in range(len(sorted_lists[0]))]\n",
    "\n",
    "pal_len = len(set(hue_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_scat = sns.scatterplot(all_proba, all_lime_stab, hue=hue_lens, palette=lime_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Stability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,1.1, 0.1))\n",
    "plt.ylim(0,1.1)\n",
    "plt.title(\"BPIC2012: Stability by Subset (LIME) \\nLSTM - 3D encoding\")\n",
    "plot = lime_scat.get_figure()\n",
    "plot.savefig(\"figures/lime_subset_stability.png\", bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "\n",
    "shap_scat = sns.scatterplot(all_proba, all_shap_stab, hue=hue_lens, palette=shap_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Stability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "plt.ylim(0,1.1)\n",
    "plt.title(\"BPIC2012: Stability by Subset (SHAP) \\nLSTM - 3D encoding\")\n",
    "plot = shap_scat.get_figure()\n",
    "plot.savefig(\"figures/shap_subset_stability.png\", bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "\n",
    "#comb = sns.FacetGrid()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_lengths, all_lime_stab, 'bo', label = \"LIME\")\n",
    "ax.plot(all_lengths, all_shap_stab, 'ro', label = \"Tree SHAP\")\n",
    "ax.set_xlabel(\"Prefix Length\")\n",
    "ax.set_ylabel(\"Stability\")\n",
    "ax.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "plt.yticks(np.arange(0,1, 0.1))\n",
    "plt.title(\"Prefix length and stability by index \\n Single Bucket with Aggregate Encoding\")\n",
    "plt.show()\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.plot(all_proba, all_lime_stab, 'bo', label = \"LIME\")\n",
    "ax2.plot(all_proba, all_shap_stab, 'ro', label = \"Tree SHAP\")\n",
    "ax2.set_xlabel(\"Prediction Probability\")\n",
    "ax2.set_ylabel(\"Stability\")\n",
    "ax2.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "plt.yticks(np.arange(0,1, 0.1))\n",
    "plt.title(\"Prediction probability and stability by index \\n Single Bucket with Aggregate Encoding\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_caseID = []\n",
    "all_lengths = []\n",
    "all_proba = []\n",
    "all_lime_stab = []\n",
    "all_shap_stab = []\n",
    "\n",
    "for dataset_name in datasets:\n",
    "\n",
    "    dataset_manager = DatasetManager(dataset_name)\n",
    "\n",
    "    for ii in range(n_iter):\n",
    "        if cls_method == \"lstm\":\n",
    "            num_buckets = 1\n",
    "        else:\n",
    "            num_buckets = len([name for name in os.listdir(os.path.join(PATH,'%s/%s_%s/models'% (dataset_ref, cls_method, method_name)))])\n",
    "        \n",
    "        \n",
    "        #if num_buckets < max_prefix:\n",
    "        #    max_prefix = num_buckets\n",
    "            \n",
    "        #buckets = range(0, max_prefix, gap)\n",
    "\n",
    "        for bucket in range(num_buckets):\n",
    "            if cls_method == \"lstm\":\n",
    "                bucketID = \"all\"\n",
    "            else:\n",
    "                bucketID = bucket+1\n",
    "            print ('Bucket', bucketID)\n",
    "\n",
    "            #import everything needed to sort and predict\n",
    "            if cls_method == \"lstm\":\n",
    "                cls_path = os.path.join(PATH, \"%s/%s_%s/cls/pred_cls.h5\" % (dataset_ref, cls_method, method_name))\n",
    "                #pred_cls = load_model(cls_path)\n",
    "            else:\n",
    "                pipeline_path = os.path.join(PATH, \"%s/%s_%s/pipelines/pipeline_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "                feat_comb_path = os.path.join(PATH, \"%s/%s_%s/bucketers_and_encoders/feature_combiner_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "                bucketer_path = os.path.join(PATH, \"%s/%s_%s/bucketers_and_encoders/bucketer_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "                cls_path = os.path.join(PATH, \"%s/%s_%s/models/cls_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "\n",
    "                predictor = joblib.load(pipeline_path)\n",
    "                cls = joblib.load(cls_path)\n",
    "                feature_combiner = joblib.load(feat_comb_path)\n",
    "                bucketer = joblib.load(bucketer_path)\n",
    "\n",
    "            #import previously identified samples\n",
    "            tn_path = os.path.join(PATH, \"%s/%s_%s/samples/true_neg_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            tp_path = os.path.join(PATH, \"%s/%s_%s/samples/true_pos_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            fn_path = os.path.join(PATH, \"%s/%s_%s/samples/false_neg_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            fp_path = os.path.join(PATH, \"%s/%s_%s/samples/false_pos_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "\n",
    "            sample_instances = []\n",
    "\n",
    "            with open (tn_path, 'rb') as f:\n",
    "                tn_list = pickle.load(f)\n",
    "            with open (tp_path, 'rb') as f:\n",
    "                tp_list = pickle.load(f)\n",
    "            with open (fn_path, 'rb') as f:\n",
    "                fn_list = pickle.load(f)\n",
    "            with open (fp_path, 'rb') as f:\n",
    "                fp_list = pickle.load(f)\n",
    "\n",
    "            #save results to a list\n",
    "            sample_instances.append(tn_list)\n",
    "            sample_instances.append(tp_list)\n",
    "            sample_instances.append(fn_list)\n",
    "            sample_instances.append(fp_list)\n",
    "            \n",
    "            type_list = [\"True Negatives\", \"True Positives\", \"False Negatives\", \"False Positives\"]\n",
    "            \n",
    "            for i in range(len(sample_instances)):\n",
    "                print (type_list[i])\n",
    "                data = pd.DataFrame.from_records(sample_instances[i])\n",
    "                \n",
    "                dispersal_lime = []\n",
    "                dispersal_shap = []\n",
    "                adj_dispersal_lime = []\n",
    "                adj_dispersal_shap = []\n",
    "                \n",
    "                case_id = pd.Series(data['caseID'])\n",
    "                nr_events = pd.Series(data['nr_events'])\n",
    "                proba = pd.Series(data['proba'])\n",
    "                lime_stability = pd.Series(data['adjusted_lime_importance_stability'])\n",
    "                tree_shap_stability = pd.Series(data['adjusted_shap_importance_stability'])\n",
    "                \n",
    "                all_caseID.extend(case_id)\n",
    "                all_lengths.extend(nr_events)\n",
    "                all_proba.extend(proba)\n",
    "                all_lime_stab.extend(lime_stability)\n",
    "                all_shap_stab.extend(tree_shap_stability)\n",
    "                \n",
    "                print(\"Average LIME Weights Stability:\", statistics.mean(lime_stability))\n",
    "                print(\"Average SHAP Weights Stability:\", statistics.mean(tree_shap_stability))\n",
    "                \n",
    "                shap_dispersion = [disp for disp in tree_shap_stability if disp > 0]\n",
    "                \n",
    "                #print (len(shap_dispersion))\n",
    "                \n",
    "                #fig, ax = plt.subplots()\n",
    "                #ax.plot(nr_events, lime_stability, 'bo', label = \"LIME\")\n",
    "                #ax.plot(nr_events, tree_shap_stability, 'ro', label = \"Tree SHAP\")\n",
    "                #ax.set_xlabel(\"Prefix Length\")\n",
    "                #ax.set_ylabel(\"Stability\")\n",
    "                #ax.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.title(\"Prefix length and stability by weight - \"+type_list[i])\n",
    "                #plt.show()\n",
    "                \n",
    "                #fig2, ax2 = plt.subplots()\n",
    "                #ax2.plot(proba, lime_stability, 'bo', label = \"LIME\")\n",
    "                #ax2.plot(proba, tree_shap_stability, 'ro', label = \"Tree SHAP\")\n",
    "                #ax2.set_xlabel(\"Prediction Probability\")\n",
    "                #ax2.set_ylabel(\"Stability\")\n",
    "                #ax2.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.title(\"Prediction probability and stability by weight - \"+type_list[i])\n",
    "                #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(all_lengths)\n",
    "bins = np.arange(0, max_len+10, 5)\n",
    "labels = []\n",
    "for i in range(len(bins)-1):\n",
    "    start = str(int(bins[i]+1))\n",
    "    end = str(int(bins[i+1]))\n",
    "    label = start+\"-\"+end+\" prefixes\"\n",
    "    labels.append(label)\n",
    "\n",
    "hue_lens = []\n",
    "for length in all_lengths:\n",
    "    cur_bin = 0\n",
    "    while length >= bins[cur_bin+1]:\n",
    "        cur_bin += 1\n",
    "    hue_lens.append(labels[cur_bin])\n",
    "#hue_lens\n",
    "\n",
    "sorted_lists = sorted(zip(all_proba, all_lime_stab, all_shap_stab, all_lengths, hue_lens), key=lambda x: x[3])\n",
    "all_proba, all_lime_stab, all_shap_stab, all_lengths, hue_lens = [[x[i] for x in sorted_lists] for i in range(len(sorted_lists[0]))]\n",
    "\n",
    "pal_len = len(set(hue_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(all_proba, all_lime_stab, hue=hue_lens, palette=lime_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Stability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,1, 0.1))\n",
    "plt.title(\"Prefix length and stability by index \\n Prefix-Length Bucket with Aggregate Encoding\")\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(all_proba, all_shap_stab, hue=hue_lens, palette=shap_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Stability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,1, 0.1))\n",
    "plt.title(\"Prefix length and stability by index \\n Prefix-Length Bucket with Aggregate Encoding\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_lengths, all_lime_stab, 'bo', label = \"LIME\")\n",
    "ax.plot(all_lengths, all_shap_stab, 'ro', label = \"Tree SHAP\")\n",
    "ax.set_xlabel(\"Prefix Length\")\n",
    "ax.set_ylabel(\"Stability\")\n",
    "ax.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,15,1))\n",
    "plt.title(\"Prefix length and stability by index \\n Prefix-Length Bucket with Aggregate Encoding\")\n",
    "plt.show()\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.plot(all_proba, all_lime_stab, 'bo', label = \"LIME\")\n",
    "ax2.plot(all_proba, all_shap_stab, 'ro', label = \"Tree SHAP\")\n",
    "ax2.set_xlabel(\"Prediction Probability\")\n",
    "ax2.set_ylabel(\"Stability\")\n",
    "ax2.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,15,1))\n",
    "plt.title(\"Prediction probability and stability by index \\n Prefix-Length Bucket with Aggregate Encoding\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_mean = np.mean(all_lime_stab)\n",
    "lime_std = np.std(all_lime_stab)\n",
    "lime_upper = lime_mean + (3*lime_std)\n",
    "lime_lower = lime_mean - (3*lime_std)\n",
    "\n",
    "shap_mean = np.mean(all_shap_stab)\n",
    "shap_std = np.std(all_shap_stab)\n",
    "shap_upper = shap_mean + (3*shap_std)\n",
    "shap_lower = shap_mean - (3*shap_std)\n",
    "\n",
    "lime_outliers = [i for i in all_lime_stab if i > lime_upper or i < lime_lower]\n",
    "shap_outliers = [i for i in all_shap_stab if i > shap_upper or i < shap_lower]\n",
    "\n",
    "print (lime_mean)\n",
    "print (shap_mean)\n",
    "print(len(lime_outliers))\n",
    "print(len(shap_outliers))\n",
    "print(str(len(lime_outliers)/len(all_lime_stab)*100)+\"%\")\n",
    "print(str(len(shap_outliers)/len(all_shap_stab)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(all_lengths)\n",
    "bins = np.arange(0, max_len+10, 5)\n",
    "labels = []\n",
    "for i in range(len(bins)-1):\n",
    "    start = str(int(bins[i]+1))\n",
    "    end = str(int(bins[i+1]))\n",
    "    label = start+\"-\"+end+\" prefixes\"\n",
    "    labels.append(label)\n",
    "\n",
    "hue_lens = []\n",
    "for length in all_lengths:\n",
    "    cur_bin = 0\n",
    "    while length >= bins[cur_bin+1]:\n",
    "        cur_bin += 1\n",
    "    hue_lens.append(labels[cur_bin])\n",
    "#hue_lens\n",
    "\n",
    "sorted_lists = sorted(zip(all_proba, all_lime_stab, all_shap_stab, all_lengths, hue_lens), key=lambda x: x[3])\n",
    "all_proba, all_lime_stab, all_shap_stab, all_lengths, hue_lens = [[x[i] for x in sorted_lists] for i in range(len(sorted_lists[0]))]\n",
    "pal_len = len(set(hue_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_scat = sns.scatterplot(all_proba, all_lime_stab, hue=hue_lens, palette=lime_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Stability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,1, 0.1))\n",
    "plt.ylim(0, 1.1)\n",
    "plt.title(\"BPIC2012: Stability by Weight (LIME) \\nLSTM - 3D encoding\")\n",
    "plot = lime_scat.get_figure()\n",
    "plot.savefig(\"figures/lime_weight_stability.png\", bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "\n",
    "shap_scat = sns.scatterplot(all_proba, all_shap_stab, hue=hue_lens, palette=shap_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Stability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,1, 0.1))\n",
    "plt.ylim(0, 1.1)\n",
    "plt.title(\"BPIC2012: Stability by Weight (SHAP) \\nLSTM - 3D encoding\")\n",
    "plot = shap_scat.get_figure()\n",
    "plot.savefig(\"figures/shap_weight_stability.png\", bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(all_lengths, all_lime_stab, 'bo', label = \"LIME\")\n",
    "ax.plot(all_lengths, all_shap_stab, 'ro', label = \"Tree SHAP\")\n",
    "ax.set_xlabel(\"Prefix Length\")\n",
    "ax.set_ylabel(\"Stability\")\n",
    "ax.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,15,1))\n",
    "plt.ylim(lime_lower, 1)\n",
    "plt.title(\"Prefix length and stability by weight \\n Single Bucket with Aggregate Encoding\")\n",
    "plt.show()\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.plot(all_proba, all_lime_stab, 'bo', label = \"LIME\")\n",
    "ax2.plot(all_proba, all_shap_stab, 'ro', label = \"Tree SHAP\")\n",
    "ax2.set_xlabel(\"Prediction Probability\")\n",
    "ax2.set_ylabel(\"Stability\")\n",
    "ax2.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,15,1))\n",
    "plt.ylim(lime_lower, 1)\n",
    "plt.title(\"Prefix length and stability by weight \\n Single Bucket with Aggregate Encoding\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = np.arange(0, shap_upper+1e-17, 1e-17)\n",
    "# yticks = np.arange(0, 120, 10)\n",
    "# #sns.set_style(\"white\")\n",
    "# plt.subplots(figsize=(20, 15))\n",
    "# plt.hist(all_shap_stab, bins = bins)\n",
    "# #plt.figsize([50, 50])\n",
    "# plt.xticks(bins, fontsize = 8)\n",
    "# plt.yticks(yticks, fontsize = 12)\n",
    "# plt.title(\"Distribution of SHAP Stability by Weight\", fontsize = 16)\n",
    "# plt.xlabel(\"Stability Range\", fontsize = 14)\n",
    "# plt.ylabel(\"Frequency\", fontsize = 14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bins = np.arange(0, lime_upper+0.1, 0.1)\n",
    "# yticks = np.arange(0, 720, 20)\n",
    "# #sns.set_style(\"white\")\n",
    "# plt.subplots(figsize=(10, 10))\n",
    "# plt.hist(all_lime_stab, bins = bins)\n",
    "# #plt.figsize([50, 50])\n",
    "# plt.xticks(bins, fontsize = 12)\n",
    "# plt.yticks(yticks, fontsize = 12)\n",
    "# plt.title(\"Distribution of LIME Stability by Weight\", fontsize = 16)\n",
    "# plt.xlabel(\"Stability Range\", fontsize = 14)\n",
    "# plt.ylabel(\"Frequency\", fontsize = 14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_caseID = []\n",
    "all_lengths = []\n",
    "all_proba = []\n",
    "\n",
    "sep_caseID = [[],[],[],[]]\n",
    "sep_lengths = [[],[],[],[]]\n",
    "sep_proba = [[],[],[],[]]\n",
    "\n",
    "all_lime_diffs = []\n",
    "all_shap_diffs = []\n",
    "\n",
    "sep_lime_diffs = [[],[],[],[]]\n",
    "sep_shap_diffs = [[],[],[],[]]\n",
    "\n",
    "all_lime_MSE = []\n",
    "all_lime_RMSE = []\n",
    "all_lime_MAE = []\n",
    "all_lime_MAPE = []\n",
    "\n",
    "sep_lime_MSE = [[],[],[],[]]\n",
    "sep_lime_RMSE = [[],[],[],[]]\n",
    "sep_lime_MAE = [[],[],[],[]]\n",
    "sep_lime_MAPE = [[],[],[],[]]\n",
    "\n",
    "all_shap_MSE = []\n",
    "all_shap_RMSE = []\n",
    "all_shap_MAE = []\n",
    "all_shap_MAPE = []\n",
    "\n",
    "sep_shap_MSE = [[],[],[],[]]\n",
    "sep_shap_RMSE = [[],[],[],[]]\n",
    "sep_shap_MAE = [[],[],[],[]]\n",
    "sep_shap_MAPE = [[],[],[],[]]\n",
    "\n",
    "for dataset_name in datasets:\n",
    "\n",
    "    dataset_manager = DatasetManager(dataset_name)\n",
    "\n",
    "    for ii in range(n_iter):\n",
    "        if cls_method == \"lstm\":\n",
    "            num_buckets = 1\n",
    "        else:\n",
    "            num_buckets = len([name for name in os.listdir(os.path.join(PATH,'%s/%s_%s/models'% (dataset_ref, cls_method, method_name)))])\n",
    "        \n",
    "        #if num_buckets < max_prefix:\n",
    "        #    max_prefix = num_buckets\n",
    "            \n",
    "        #buckets = range(0, max_prefix, gap)\n",
    "\n",
    "        for bucket in range(num_buckets):\n",
    "            bucketID = \"all\"\n",
    "            print ('Bucket', bucketID)\n",
    "\n",
    "            #import everything needed to sort and predict\n",
    "            if cls_method == \"lstm\":\n",
    "                cls_path = os.path.join(PATH, \"%s/%s_%s/cls/pred_cls.h5\" % (dataset_ref, cls_method, method_name))\n",
    "                #pred_cls = load_model(cls_path)\n",
    "            else:\n",
    "                pipeline_path = os.path.join(PATH, \"%s/%s_%s/pipelines/pipeline_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "                feat_comb_path = os.path.join(PATH, \"%s/%s_%s/bucketers_and_encoders/feature_combiner_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "                bucketer_path = os.path.join(PATH, \"%s/%s_%s/bucketers_and_encoders/bucketer_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "                cls_path = os.path.join(PATH, \"%s/%s_%s/models/cls_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "\n",
    "                predictor = joblib.load(pipeline_path)\n",
    "                cls = joblib.load(cls_path)\n",
    "                feature_combiner = joblib.load(feat_comb_path)\n",
    "                bucketer = joblib.load(bucketer_path)\n",
    "\n",
    "            #import previously identified samples\n",
    "            tn_path = os.path.join(PATH, \"%s/%s_%s/samples/true_neg_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            tp_path = os.path.join(PATH, \"%s/%s_%s/samples/true_pos_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            fn_path = os.path.join(PATH, \"%s/%s_%s/samples/false_neg_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            fp_path = os.path.join(PATH, \"%s/%s_%s/samples/false_pos_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "\n",
    "            sample_instances = []\n",
    "\n",
    "            with open (tn_path, 'rb') as f:\n",
    "                tn_list = pickle.load(f)\n",
    "            with open (tp_path, 'rb') as f:\n",
    "                tp_list = pickle.load(f)\n",
    "            with open (fn_path, 'rb') as f:\n",
    "                fn_list = pickle.load(f)\n",
    "            with open (fp_path, 'rb') as f:\n",
    "                fp_list = pickle.load(f)\n",
    "\n",
    "            #save results to a list\n",
    "            sample_instances.append(tn_list)\n",
    "            sample_instances.append(tp_list)\n",
    "            sample_instances.append(fn_list)\n",
    "            sample_instances.append(fp_list)\n",
    "            \n",
    "            type_list = [\"True Negatives\", \"True Positives\", \"False Negatives\", \"False Positives\"]\n",
    "            \n",
    "            for i in range(len(sample_instances)):\n",
    "                print (type_list[i])\n",
    "                data = pd.DataFrame.from_records(sample_instances[i])\n",
    "                \n",
    "                lime_MSE = []\n",
    "                lime_RMSE = []\n",
    "                lime_MAE = []\n",
    "                lime_MAPE = []\n",
    "                \n",
    "                shap_MSE = []\n",
    "                shap_RMSE = []\n",
    "                shap_MAE = []\n",
    "                shap_MAPE = []\n",
    "                \n",
    "                case_id = pd.Series(data['caseID'])\n",
    "                nr_events = pd.Series(data['nr_events'])\n",
    "                proba = pd.Series(data['proba'])\n",
    "                lime_diffs = pd.Series(data['lime_fid_change'])\n",
    "                shap_diffs = pd.Series(data['shap_fid_change'])\n",
    "                \n",
    "                for j in range(len(lime_diffs)):\n",
    "                    p1 = proba[j]\n",
    "                    \n",
    "                    lime_diff = lime_diffs[j]\n",
    "                    shap_diff = shap_diffs[j]\n",
    "                    \n",
    "                    all_lime_diffs.append(lime_diff)\n",
    "                    all_shap_diffs.append(shap_diff)\n",
    "                    \n",
    "                    lime_sq_changes = []\n",
    "                    lime_abs_changes = []\n",
    "                    lime_rel_changes = []\n",
    "                    \n",
    "                    shap_sq_changes = []\n",
    "                    shap_abs_changes = []\n",
    "                    shap_rel_changes = []\n",
    "                    \n",
    "                    for each in lime_diff:\n",
    "                        lime_sq_changes.append(each**2)\n",
    "                        lime_abs_changes.append(abs(each))\n",
    "                        lime_rel_changes.append(abs(each)/p1)\n",
    "                        \n",
    "                    for each in shap_diff:\n",
    "                        shap_sq_changes.append(each**2)\n",
    "                        shap_abs_changes.append(abs(each))\n",
    "                        shap_rel_changes.append(abs(each)/p1)\n",
    "                    \n",
    "                    lime_MSE.append(sum(lime_sq_changes)/len(lime_sq_changes))\n",
    "                    lime_RMSE.append(math.sqrt(sum(lime_sq_changes)/len(lime_sq_changes)))\n",
    "                    lime_MAE.append(sum(lime_abs_changes)/len(lime_abs_changes))\n",
    "                    lime_MAPE.append(sum(lime_rel_changes)/len(lime_rel_changes))\n",
    "                    \n",
    "                    shap_MSE.append(sum(shap_sq_changes)/len(shap_sq_changes))\n",
    "                    shap_RMSE.append(math.sqrt(sum(shap_sq_changes)/len(shap_sq_changes)))\n",
    "                    shap_MAE.append(sum(shap_abs_changes)/len(shap_abs_changes))\n",
    "                    shap_MAPE.append(sum(shap_rel_changes)/len(shap_rel_changes))\n",
    "                \n",
    "                all_caseID.extend(case_id)\n",
    "                all_lengths.extend(nr_events)\n",
    "                all_proba.extend(proba)\n",
    "                \n",
    "                all_lime_MSE.extend(lime_MSE)\n",
    "                all_lime_RMSE.extend(lime_RMSE)\n",
    "                all_lime_MAE.extend(lime_MAE)\n",
    "                all_lime_MAPE.extend(lime_MAPE)\n",
    "                \n",
    "                all_shap_MSE.extend(shap_MSE)\n",
    "                all_shap_RMSE.extend(shap_RMSE)\n",
    "                all_shap_MAE.extend(shap_MAE)\n",
    "                all_shap_MAPE.extend(shap_MAPE)\n",
    "                \n",
    "                sep_caseID[i].extend(case_id)\n",
    "                sep_lengths[i].extend(nr_events)\n",
    "                sep_proba[i].extend(proba)\n",
    "                \n",
    "                sep_lime_MSE[i].extend(lime_MSE)\n",
    "                sep_lime_RMSE[i].extend(lime_RMSE)\n",
    "                sep_lime_MAE[i].extend(lime_MAE)\n",
    "                sep_lime_MAPE[i].extend(lime_MAPE)\n",
    "                \n",
    "                sep_shap_MSE[i].extend(shap_MSE)\n",
    "                sep_shap_RMSE[i].extend(shap_RMSE)\n",
    "                sep_shap_MAE[i].extend(shap_MAE)\n",
    "                sep_shap_MAPE[i].extend(shap_MAPE)\n",
    "                \n",
    "                print(\"Average LIME MSE:\", statistics.mean(lime_MSE))\n",
    "                print(\"Average SHAP MSE:\", statistics.mean(shap_MSE))\n",
    "                print(\"\\n\")\n",
    "                \n",
    "                #plt.plot(nr_events, lime_MSE, 'bo', label = \"LIME\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prefix length and MSE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.plot(nr_events, shap_MSE, 'ro', label = \"Tree SHAP\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                ##plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prefix length and MSE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.plot(proba, lime_MSE, 'bo', label = \"LIME\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prediction probability and MSE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.plot(proba, shap_MSE, 'ro', label = \"Tree SHAP\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prediction probability and MSE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "                \n",
    "                print(\"Average LIME RMSE:\", statistics.mean(lime_RMSE))\n",
    "                print(\"Average SHAP RMSE:\", statistics.mean(shap_RMSE))\n",
    "                print(\"\\n\")\n",
    "                \n",
    "                #plt.plot(nr_events, lime_RMSE, 'bo', label = \"LIME\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prefix length and RMSE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.plot(nr_events, shap_RMSE, 'ro', label = \"Tree SHAP\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prefix length and RMSE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.plot(proba, lime_RMSE, 'bo', label = \"LIME\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prediction probability and RMSE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.plot(proba, shap_RMSE, 'ro', label = \"Tree SHAP\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prediction probability and RMSE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "                \n",
    "                print(\"Average LIME MAE:\", statistics.mean(lime_MAE))\n",
    "                print(\"Average SHAP MAE:\", statistics.mean(shap_MAE))\n",
    "                print(\"\\n\")\n",
    "                \n",
    "                #plt.plot(nr_events, lime_MAE, 'bo', label = \"LIME\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prefix length and MAE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.plot(nr_events, shap_MAE, 'ro', label = \"Tree SHAP\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prefix length and MAE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.plot(proba, lime_MAE, 'bo', label = \"LIME\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prediction probability and MAE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.plot(proba, shap_MAE, 'ro', label = \"Tree SHAP\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prediction probability and MAE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "                \n",
    "                print(\"Average LIME MAPE:\", statistics.mean(lime_MAPE))\n",
    "                print(\"Average SHAP MAPE:\", statistics.mean(shap_MAPE))\n",
    "                print(\"\\n\")\n",
    "                \n",
    "                #plt.plot(nr_events, lime_MAPE, 'bo', label = \"LIME\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prefix length and MAPE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.plot(nr_events, shap_MAPE, 'ro', label = \"Tree SHAP\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prefix length and MAPE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.plot(proba, lime_MAPE, 'bo', label = \"LIME\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prediction probability and MAPE \\n\"+type_list[i])\n",
    "                #plt.show()\n",
    "\n",
    "                #plt.plot(proba, shap_MAPE, 'ro', label = \"Tree SHAP\")\n",
    "                #plt.xlabel(\"Prefix Length\")\n",
    "                #plt.ylabel(\"Change in Prediction Probability\")\n",
    "                #plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "                #plt.yticks(np.arange(0,15,1))\n",
    "                #plt.title(\"Prediction probability and MAPE \\n\"+type_list[i])\n",
    "                #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(all_lengths)\n",
    "bins = np.arange(0, max_len+10, 5)\n",
    "labels = []\n",
    "for i in range(len(bins)-1):\n",
    "    start = str(int(bins[i]+1))\n",
    "    end = str(int(bins[i+1]))\n",
    "    label = start+\"-\"+end+\" prefixes\"\n",
    "    labels.append(label)\n",
    "\n",
    "hue_lens = []\n",
    "for length in all_lengths:\n",
    "    cur_bin = 0\n",
    "    while length >= bins[cur_bin+1]:\n",
    "        cur_bin += 1\n",
    "    hue_lens.append(labels[cur_bin])\n",
    "#hue_lens\n",
    "\n",
    "sorted_lists = sorted(zip(all_proba, all_lime_MSE, all_shap_MSE, all_lime_RMSE, all_shap_RMSE, all_lime_MAE, all_shap_MAE, \n",
    "                          all_lime_MAPE, all_shap_MAPE, all_lengths, hue_lens), key=lambda x: x[-2])\n",
    "all_proba, all_lime_MSE, all_shap_MSE, all_lime_RMSE, all_shap_RMSE, all_lime_MAE, all_shap_MAE, all_lime_MAPE, all_shap_MAPE, all_lengths, hue_lens = [[x[i] for x in sorted_lists] for i in range(len(sorted_lists[0]))]\n",
    "pal_len = len(set(hue_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(all_proba, all_lime_MSE, hue = hue_lens, palette = lime_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Change in Prediction Probability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,15,1))\n",
    "plt.title(\"BPIC2012: Fidelity: MSE (LIME) \\nLSTM - 3D encoding\")\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(all_proba, all_shap_MSE, hue = hue_lens, palette = shap_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Change in Prediction Probability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,15,1))\n",
    "plt.title(\"BPIC2012: Fidelity: MSE (SHAP) \\nLSTM - 3D encoding\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(all_proba, all_lime_RMSE, hue = hue_lens, palette = lime_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Change in Prediction Probability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,15,1))\n",
    "plt.title(\"BPIC2012: Fidelity: RMSE (LIME) \\nLSTM - 3D encoding\")\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(all_proba, all_shap_RMSE, hue = hue_lens, palette = shap_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Change in Prediction Probability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,15,1))\n",
    "plt.title(\"BPIC2012: Fidelity: RMSE (SHAP) \\nLSTM - 3D encoding\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_scat = sns.scatterplot(all_proba, all_lime_MAE, hue = hue_lens, palette = lime_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Change in Prediction Probability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,15,1))\n",
    "plt.title(\"BPIC2012: Fidelity: MAE (LIME) \\nLSTM - 3D encoding\")\n",
    "plot = lime_scat.get_figure()\n",
    "plot.savefig(\"figures/lime_fidelity_mae.png\", bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "\n",
    "shap_scat = sns.scatterplot(all_proba, all_shap_MAE, hue = hue_lens, palette = shap_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Change in Prediction Probability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,15,1))\n",
    "plt.title(\"BPIC2012: Fidelity: MAE (SHAP) \\nLSTM - 3D encoding\")\n",
    "plot = shap_scat.get_figure()\n",
    "plot.savefig(\"figures/shap_fidelity_mae.png\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_scat = sns.scatterplot(all_proba, all_lime_MAPE, hue = hue_lens, palette = lime_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Change in Prediction Probability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,15,1))\n",
    "plt.title(\"BPIC2012: Fidelity: MAPE (LIME) \\nLSTM - 3D encoding\")\n",
    "plot = lime_scat.get_figure()\n",
    "plot.savefig(\"figures/lime_fidelity_mape.png\", bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "\n",
    "shap_scat = sns.scatterplot(all_proba, all_shap_MAPE, hue = hue_lens, palette = shap_pal[:pal_len])\n",
    "plt.xlabel(\"Prediction Probability\")\n",
    "plt.ylabel(\"Change in Prediction Probability\")\n",
    "plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "#plt.yticks(np.arange(0,15,1))\n",
    "plt.title(\"BPIC2012: Fidelity: MAPE (SHAP) \\nLSTM - 3D encoding\")\n",
    "plot = shap_scat.get_figure()\n",
    "plot.savefig(\"figures/shap_fidelity_mape.png\", bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(all_lengths)\n",
    "bins = np.arange(0, max_len+10, 5)\n",
    "labels = []\n",
    "for i in range(len(bins)-1):\n",
    "    start = str(int(bins[i]+1))\n",
    "    end = str(int(bins[i+1]))\n",
    "    label = start+\"-\"+end+\" prefixes\"\n",
    "    labels.append(label)\n",
    "\n",
    "sep_hues = [[],[],[],[]]\n",
    "\n",
    "for i in range(len(sep_lengths)): \n",
    "    for length in sep_lengths[i]:\n",
    "        cur_bin = 0\n",
    "        while length >= bins[cur_bin+1]:\n",
    "            cur_bin += 1\n",
    "        sep_hues[i].append(labels[cur_bin])\n",
    "#sep_hues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type_list = ['True Negative', 'True Positive', 'False Negative', 'False Positive']\n",
    "\n",
    "for i in range(len(type_list)):\n",
    "    sns.scatterplot(sep_proba[i], sep_lime_MSE[i], hue = sep_hues[i], palette = lime_pal[:len(set(sep_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - LIME: Prediction probability and MSE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(sep_proba[i], sep_shap_MSE[i], hue = sep_hues[i], palette = shap_pal[:len(set(sep_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - SHAP: Prediction probability and MSE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list = ['True Negative', 'True Positive', 'False Negative', 'False Positive']\n",
    "\n",
    "for i in range(len(type_list)):\n",
    "    sns.scatterplot(sep_proba[i], sep_lime_RMSE[i], hue = sep_hues[i], palette = lime_pal[:len(set(sep_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - LIME: Prediction probability and RMSE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(sep_proba[i], sep_shap_RMSE[i], hue = sep_hues[i], palette = shap_pal[:len(set(sep_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - SHAP: Prediction probability and RMSE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list = ['True Negative', 'True Positive', 'False Negative', 'False Positive']\n",
    "\n",
    "for i in range(len(type_list)):\n",
    "    sns.scatterplot(sep_proba[i], sep_lime_MAE[i], hue = sep_hues[i], palette = lime_pal[:len(set(sep_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - LIME: Prediction probability and MAE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(sep_proba[i], sep_shap_MAE[i], hue = sep_hues[i], palette = shap_pal[:len(set(sep_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - SHAP: Prediction probability and MAE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type_list = ['True Negative', 'True Positive', 'False Negative', 'False Positive']\n",
    "\n",
    "for i in range(len(type_list)):\n",
    "    sns.scatterplot(sep_proba[i], sep_lime_MAPE[i], hue = sep_hues[i], palette = lime_pal[:len(set(sep_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - LIME: Prediction probability and MAPE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(sep_proba[i], sep_shap_MAPE[i], hue = sep_hues[i], palette = shap_pal[:len(set(sep_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - SHAP: Prediction probability and MAPE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type_list = ['Negatives', 'Positives']\n",
    "\n",
    "type_lengths = [[], []]\n",
    "type_proba = [[],[]]\n",
    "type_hues = [[],[]]\n",
    "\n",
    "type_hues[0].extend(sep_hues[0])\n",
    "type_hues[0].extend(sep_hues[2])\n",
    "type_hues[1].extend(sep_hues[1])\n",
    "type_hues[1].extend(sep_hues[3])\n",
    "\n",
    "type_lengths[0].extend(sep_lengths[0])\n",
    "type_lengths[0].extend(sep_lengths[2])\n",
    "type_lengths[1].extend(sep_lengths[1])\n",
    "type_lengths[1].extend(sep_lengths[3])\n",
    "\n",
    "type_proba[0].extend(sep_proba[0])\n",
    "type_proba[0].extend(sep_proba[2])\n",
    "type_proba[1].extend(sep_proba[1])\n",
    "type_proba[1].extend(sep_proba[3])\n",
    "\n",
    "type_lime_MSE = [[],[]]\n",
    "type_shap_MSE = [[],[]]\n",
    "\n",
    "type_lime_MSE[0].extend(sep_lime_MSE[0])\n",
    "type_lime_MSE[0].extend(sep_lime_MSE[2])\n",
    "type_lime_MSE[1].extend(sep_lime_MSE[1])\n",
    "type_lime_MSE[1].extend(sep_lime_MSE[3])\n",
    "\n",
    "type_shap_MSE[0].extend(sep_shap_MSE[0])\n",
    "type_shap_MSE[0].extend(sep_shap_MSE[2])\n",
    "type_shap_MSE[1].extend(sep_shap_MSE[1])\n",
    "type_shap_MSE[1].extend(sep_shap_MSE[3])\n",
    "\n",
    "for i in range(len(type_list)):\n",
    "    sns.scatterplot(type_proba[i], type_lime_MSE[i], hue = type_hues[i], palette = lime_pal[:len(set(type_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - LIME: Prediction probability and MSE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(type_proba[i], type_shap_MSE[i], hue = type_hues[i], palette = shap_pal[:len(set(type_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - SHAP: Prediction probability and MSE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type_list = ['Negatives', 'Positives']\n",
    "\n",
    "type_lengths = [[], []]\n",
    "type_proba = [[],[]]\n",
    "\n",
    "type_lengths[0].extend(sep_lengths[0])\n",
    "type_lengths[0].extend(sep_lengths[2])\n",
    "type_lengths[1].extend(sep_lengths[1])\n",
    "type_lengths[1].extend(sep_lengths[3])\n",
    "\n",
    "type_proba[0].extend(sep_proba[0])\n",
    "type_proba[0].extend(sep_proba[2])\n",
    "type_proba[1].extend(sep_proba[1])\n",
    "type_proba[1].extend(sep_proba[3])\n",
    "\n",
    "type_lime_RMSE = [[],[]]\n",
    "type_shap_RMSE = [[],[]]\n",
    "\n",
    "type_lime_RMSE[0].extend(sep_lime_RMSE[0])\n",
    "type_lime_RMSE[0].extend(sep_lime_RMSE[2])\n",
    "type_lime_RMSE[1].extend(sep_lime_RMSE[1])\n",
    "type_lime_RMSE[1].extend(sep_lime_RMSE[3])\n",
    "\n",
    "type_shap_RMSE[0].extend(sep_shap_RMSE[0])\n",
    "type_shap_RMSE[0].extend(sep_shap_RMSE[2])\n",
    "type_shap_RMSE[1].extend(sep_shap_RMSE[1])\n",
    "type_shap_RMSE[1].extend(sep_shap_RMSE[3])\n",
    "\n",
    "for i in range(len(type_list)):\n",
    "    sns.scatterplot(type_proba[i], type_lime_RMSE[i], hue = type_hues[i], palette = lime_pal[:len(set(type_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - LIME: Prediction probability and RMSE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(type_proba[i], type_shap_RMSE[i], hue = type_hues[i], palette = shap_pal[:len(set(type_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - SHAP: Prediction probability and RMSE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type_list = ['Negatives', 'Positives']\n",
    "\n",
    "type_lengths = [[], []]\n",
    "type_proba = [[],[]]\n",
    "\n",
    "type_lengths[0].extend(sep_lengths[0])\n",
    "type_lengths[0].extend(sep_lengths[2])\n",
    "type_lengths[1].extend(sep_lengths[1])\n",
    "type_lengths[1].extend(sep_lengths[3])\n",
    "\n",
    "type_proba[0].extend(sep_proba[0])\n",
    "type_proba[0].extend(sep_proba[2])\n",
    "type_proba[1].extend(sep_proba[1])\n",
    "type_proba[1].extend(sep_proba[3])\n",
    "\n",
    "type_lime_MAE = [[],[]]\n",
    "type_shap_MAE = [[],[]]\n",
    "\n",
    "type_lime_MAE[0].extend(sep_lime_MAE[0])\n",
    "type_lime_MAE[0].extend(sep_lime_MAE[2])\n",
    "type_lime_MAE[1].extend(sep_lime_MAE[1])\n",
    "type_lime_MAE[1].extend(sep_lime_MAE[3])\n",
    "\n",
    "type_shap_MAE[0].extend(sep_shap_MAE[0])\n",
    "type_shap_MAE[0].extend(sep_shap_MAE[2])\n",
    "type_shap_MAE[1].extend(sep_shap_MAE[1])\n",
    "type_shap_MAE[1].extend(sep_shap_MAE[3])\n",
    "\n",
    "for i in range(len(type_list)):\n",
    "    sns.scatterplot(type_proba[i], type_lime_MAE[i], hue = type_hues[i], palette = lime_pal[:len(set(type_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - LIME: Prediction probability and MAE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(type_proba[i], type_shap_MAE[i], hue = type_hues[i], palette = shap_pal[:len(set(type_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - SHAP: Prediction probability and MAE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type_list = ['Negatives', 'Positives']\n",
    "\n",
    "type_lengths = [[], []]\n",
    "type_proba = [[],[]]\n",
    "\n",
    "type_lengths[0].extend(sep_lengths[0])\n",
    "type_lengths[0].extend(sep_lengths[2])\n",
    "type_lengths[1].extend(sep_lengths[1])\n",
    "type_lengths[1].extend(sep_lengths[3])\n",
    "\n",
    "type_proba[0].extend(sep_proba[0])\n",
    "type_proba[0].extend(sep_proba[2])\n",
    "type_proba[1].extend(sep_proba[1])\n",
    "type_proba[1].extend(sep_proba[3])\n",
    "\n",
    "type_lime_MAPE = [[],[]]\n",
    "type_shap_MAPE = [[],[]]\n",
    "\n",
    "type_lime_MAPE[0].extend(sep_lime_MAPE[0])\n",
    "type_lime_MAPE[0].extend(sep_lime_MAPE[2])\n",
    "type_lime_MAPE[1].extend(sep_lime_MAPE[1])\n",
    "type_lime_MAPE[1].extend(sep_lime_MAPE[3])\n",
    "\n",
    "type_shap_MAPE[0].extend(sep_shap_MAPE[0])\n",
    "type_shap_MAPE[0].extend(sep_shap_MAPE[2])\n",
    "type_shap_MAPE[1].extend(sep_shap_MAPE[1])\n",
    "type_shap_MAPE[1].extend(sep_shap_MAPE[3])\n",
    "\n",
    "for i in range(len(type_list)):\n",
    "    sns.scatterplot(type_proba[i], type_lime_MAPE[i], hue = type_hues[i], palette = lime_pal[:len(set(type_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - LIME: Prediction probability and MAPE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n",
    "\n",
    "    sns.scatterplot(type_proba[i], type_shap_MAPE[i], hue = type_hues[i], palette = shap_pal[:len(set(type_hues[i]))])\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Change in Prediction Probability\")\n",
    "    plt.legend(frameon = False, bbox_to_anchor=(1, 1), loc = 'upper left')\n",
    "    #plt.yticks(np.arange(0,15,1))\n",
    "    plt.title(type_list[i]+\" - SHAP: Prediction probability and MAPE \\nPrefix-length Bucket with Aggregate Encoding\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average LIME MSE:\", np.mean(all_lime_MSE))\n",
    "print(\"Average SHAP MSE:\", np.mean(all_shap_MSE))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average LIME RMSE:\", np.mean(all_lime_RMSE))\n",
    "print(\"Average SHAP RMSE:\", np.mean(all_shap_RMSE))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average LIME MAE:\", np.mean(all_lime_MAE))\n",
    "print(\"Average SHAP MAE:\", np.mean(all_shap_MAE))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average LIME MAPE:\", np.mean(all_lime_MAPE))\n",
    "print(\"Average SHAP MAPE:\", np.mean(all_shap_MAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
