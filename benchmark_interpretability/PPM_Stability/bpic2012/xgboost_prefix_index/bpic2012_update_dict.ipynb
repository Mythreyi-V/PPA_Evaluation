{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "import sys\n",
    "#PATH = '/content/drive/My Drive/PPM_Stability/'\n",
    "PATH = \"C:/Users/velmurug/Documents/Stability Experiments/benchmark_interpretability/PPM_Stability/\"\n",
    "#PATH = \"C:/Users/Mythreyi/Documents/GitHub/Stability-Experiments/benchmark_interpretability/PPM_Stability/\"\n",
    "#PATH = \"C:/Users/mythr/Documents/GitHub/Stability-Experiments/benchmark_interpretability/PPM_Stability/\"\n",
    "sys.path.append(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DatasetManager import DatasetManager\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from sys import argv\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "import statistics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bpic2012_accepted']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ref = \"bpic2012\"\n",
    "params_dir = PATH + \"params\"\n",
    "results_dir = \"results\"\n",
    "bucket_method = \"prefix\"\n",
    "cls_encoding = \"index\"\n",
    "cls_method = \"xgboost\"\n",
    "\n",
    "gap = 1\n",
    "n_iter = 1\n",
    "\n",
    "method_name = \"%s_%s\"%(bucket_method, cls_encoding)\n",
    "\n",
    "generate_samples = False\n",
    "generate_lime = True\n",
    "generate_kernel_shap = False\n",
    "generate_model_shap = True\n",
    "\n",
    "sample_size = 2\n",
    "exp_iter = 10\n",
    "max_feat = 10\n",
    "\n",
    "dataset_ref_to_datasets = {\n",
    "    #\"bpic2011\": [\"bpic2011_f%s\"%formula for formula in range(1,5)],\n",
    "    \"bpic2015\": [\"bpic2015_%s_f2\"%(municipality) for municipality in range(5,6)],\n",
    "    \"bpic2017\" : [\"bpic2017_accepted\"],\n",
    "    \"bpic2012\" : [\"bpic2012_accepted\"]\n",
    "    #\"insurance\": [\"insurance_activity\", \"insurance_followup\"],\n",
    "    #\"sepsis_cases\": [\"sepsis_cases_1\", \"sepsis_cases_2\", \"sepsis_cases_4\"]\n",
    "}\n",
    "\n",
    "datasets = [dataset_ref] if dataset_ref not in dataset_ref_to_datasets else dataset_ref_to_datasets[dataset_ref]\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'lime_weights_dispersal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-78dd2bd7cc39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mlis\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_instances\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                     \u001b[0mdispersal_lime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meach\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lime_weights_dispersal'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m                     \u001b[0mdispersal_shap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meach\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shap_weights_dispersal'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                     \u001b[0madj_dispersal_lime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meach\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'adjusted_lime_weights_dispersal'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lime_weights_dispersal'"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "\n",
    "    dataset_manager = DatasetManager(dataset_name)\n",
    "\n",
    "    for ii in range(n_iter):\n",
    "        num_buckets = range(len([name for name in os.listdir(os.path.join(PATH,'%s/%s_%s/models'% (dataset_ref, cls_method, method_name)))]))\n",
    "\n",
    "        for bucket in list(num_buckets):\n",
    "            bucketID = bucket+1\n",
    "            print ('Bucket', bucketID)\n",
    "\n",
    "            #import everything needed to sort and predict\n",
    "            feat_comb_path = os.path.join(PATH, \"%s/%s_%s/bucketers_and_encoders/feature_combiner_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            cls_path = os.path.join(PATH, \"%s/%s_%s/models/cls_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            cls = joblib.load(cls_path)\n",
    "            feature_combiner = joblib.load(feat_comb_path)\n",
    "\n",
    "            #import previously identified samples\n",
    "            tn_path = os.path.join(PATH, \"%s/%s_%s/samples/true_neg_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            tp_path = os.path.join(PATH, \"%s/%s_%s/samples/true_pos_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            fn_path = os.path.join(PATH, \"%s/%s_%s/samples/false_neg_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            fp_path = os.path.join(PATH, \"%s/%s_%s/samples/false_pos_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "\n",
    "            sample_instances = []\n",
    "\n",
    "            with open (tn_path, 'rb') as f:\n",
    "                tn_list = pickle.load(f)\n",
    "            with open (tp_path, 'rb') as f:\n",
    "                tp_list = pickle.load(f)\n",
    "            with open (fn_path, 'rb') as f:\n",
    "                fn_list = pickle.load(f)\n",
    "            with open (fp_path, 'rb') as f:\n",
    "                fp_list = pickle.load(f)\n",
    "\n",
    "            #save results to a list\n",
    "            sample_instances.append(tn_list)\n",
    "            sample_instances.append(tp_list)\n",
    "            sample_instances.append(fn_list)\n",
    "            sample_instances.append(fp_list)\n",
    "            \n",
    "            \n",
    "            for lis in sample_instances:\n",
    "                for each in lis:\n",
    "                    dispersal_lime = each['lime_weights_dispersal']\n",
    "                    dispersal_shap = each['shap_weights_dispersal']\n",
    "                    adj_dispersal_lime = each['adjusted_lime_weights_dispersal']\n",
    "                    adj_dispersal_shap = each['adjusted_shap_weights_dispersal']\n",
    "                    \n",
    "                    lime_stability = np.mean(dispersal_lime)\n",
    "                    shap_stability = np.mean(dispersal_shap)\n",
    "                    adj_lime_stability = np.mean(adj_dispersal_lime)\n",
    "                    adj_shap_stability = np.mean(adj_dispersal_shap)\n",
    "                    \n",
    "                    each['lime_importance_stability'] = lime_stability\n",
    "                    each['shap_importance_stability'] = shap_stability\n",
    "                    each['adjusted_lime_importance_stability'] = adj_lime_stability\n",
    "                    each['adjusted_shap_importance_stability'] = adj_shap_stability\n",
    "\n",
    "            with open (tn_path, 'wb') as f:\n",
    "                pickle.dump(sample_instances[0], f)\n",
    "            with open (tp_path, 'wb') as f:\n",
    "                pickle.dump(sample_instances[1], f)\n",
    "            with open (fn_path, 'wb') as f:\n",
    "                pickle.dump(sample_instances[2], f)\n",
    "            with open (fp_path, 'wb') as f:\n",
    "                pickle.dump(sample_instances[3], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'caseID': '204628',\n",
       " 'input':         AMOUNT_REQ Case ID    label              Activity Resource  \\\n",
       " 151722     45000.0  204628  deviant  A_SUBMITTED-COMPLETE    112.0   \n",
       " \n",
       "        lifecycle:transition  timesincemidnight  timesincelastevent  \\\n",
       " 151722             COMPLETE              966.0                 0.0   \n",
       " \n",
       "         timesincecasestart  event_nr  month  weekday  hour  open_cases  \\\n",
       " 151722                 0.0       1.0    1.0      5.0  16.0       837.0   \n",
       " \n",
       "             Complete Timestamp  case_length  prefix_nr orig_case_id  \n",
       " 151722 2012-01-28 16:06:17.749           40          1       204628  ,\n",
       " 'actual': 1,\n",
       " 'predicted': 0,\n",
       " 'proba': 0.5373451411724091,\n",
       " 'nr_events': 1,\n",
       " 'pred_type': 'FN',\n",
       " 'tree_shap_stability': 1.0,\n",
       " 'shap_weights_dispersal': [5.04873383009714e-16,\n",
       "  0.0,\n",
       "  6.111125726756219e-16,\n",
       "  1.2825063069302494e-15,\n",
       "  0.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  9.914708344218805e-16,\n",
       "  0,\n",
       "  0],\n",
       " 'adjusted_shap_weights_dispersal': [5.04873383009714e-16,\n",
       "  0.0,\n",
       "  6.111125726756219e-16,\n",
       "  1.2825063069302494e-15,\n",
       "  0.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  9.914708344218805e-16,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
