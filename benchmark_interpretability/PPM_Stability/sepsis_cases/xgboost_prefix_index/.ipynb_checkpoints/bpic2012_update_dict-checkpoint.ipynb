{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28148,
     "status": "ok",
     "timestamp": 1604719793115,
     "user": {
      "displayName": "Mythreyi Velmurugan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh6DP4Hn-qpp593Bc6lrayXXcdQv42KAS3zJ-Ay=s64",
      "userId": "09509504425224260690"
     },
     "user_tz": -600
    },
    "id": "Oha-u4UeWdBY",
    "outputId": "fda3e57a-d68c-47da-aca2-0fa3501df04d"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "import sys\n",
    "#PATH = '/content/drive/My Drive/PPM_Stability/'\n",
    "#PATH = \"C:/Users/velmurug/Documents/Stability Experiments/benchmark_interpretability/PPM_Stability/\"\n",
    "#PATH = \"C:/Users/Mythreyi/Documents/GitHub/Stability-Experiments/benchmark_interpretability/PPM_Stability/\"\n",
    "PATH = \"C:/Users/mythr/Documents/GitHub/Stability-Experiments/benchmark_interpretability/PPM_Stability/\"\n",
    "#PATH = \"C:/Users/n9455647/Documents/GitHub/Stability-Experiments/benchmark_interpretability/PPM_Stability/\"\n",
    "sys.path.append(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 30304,
     "status": "ok",
     "timestamp": 1604719795269,
     "user": {
      "displayName": "Mythreyi Velmurugan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh6DP4Hn-qpp593Bc6lrayXXcdQv42KAS3zJ-Ay=s64",
      "userId": "09509504425224260690"
     },
     "user_tz": -600
    },
    "id": "tHv_lUq7WdBc"
   },
   "outputs": [],
   "source": [
    "from DatasetManager import DatasetManager\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from sys import argv\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "import statistics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30279,
     "status": "ok",
     "timestamp": 1604719795290,
     "user": {
      "displayName": "Mythreyi Velmurugan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh6DP4Hn-qpp593Bc6lrayXXcdQv42KAS3zJ-Ay=s64",
      "userId": "09509504425224260690"
     },
     "user_tz": -600
    },
    "id": "m_JNfYYnWdBf",
    "outputId": "7c4b6502-84cb-4004-e2b9-c57b6103cee9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepsis_cases_1']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ref = \"sepsis_cases\"\n",
    "params_dir = PATH + \"params\"\n",
    "results_dir = \"results\"\n",
    "bucket_method = \"prefix\"\n",
    "cls_encoding = \"index\"\n",
    "cls_method = \"xgboost\"\n",
    "\n",
    "gap = 1\n",
    "n_iter = 1\n",
    "\n",
    "method_name = \"%s_%s\"%(bucket_method, cls_encoding)\n",
    "\n",
    "generate_samples = False\n",
    "generate_lime = True\n",
    "generate_kernel_shap = False\n",
    "generate_model_shap = True\n",
    "\n",
    "sample_size = 2\n",
    "exp_iter = 10\n",
    "max_feat = 10\n",
    "max_prefix = 20\n",
    "\n",
    "dataset_ref_to_datasets = {\n",
    "    #\"bpic2011\": [\"bpic2011_f%s\"%formula for formula in range(1,5)],\n",
    "    \"bpic2015\": [\"bpic2015_%s_f2\"%(municipality) for municipality in range(5,6)],\n",
    "    \"bpic2017\" : [\"bpic2017_accepted\"],\n",
    "    \"bpic2012\" : [\"bpic2012_accepted\"],\n",
    "    #\"insurance\": [\"insurance_activity\", \"insurance_followup\"],\n",
    "    \"sepsis_cases\": [\"sepsis_cases_1\"]#, \"sepsis_cases_2\", \"sepsis_cases_4\"]\n",
    "}\n",
    "\n",
    "datasets = [dataset_ref] if dataset_ref not in dataset_ref_to_datasets else dataset_ref_to_datasets[dataset_ref]\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51385,
     "status": "ok",
     "timestamp": 1604719816405,
     "user": {
      "displayName": "Mythreyi Velmurugan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh6DP4Hn-qpp593Bc6lrayXXcdQv42KAS3zJ-Ay=s64",
      "userId": "09509504425224260690"
     },
     "user_tz": -600
    },
    "id": "lRh4KLltWdBj",
    "outputId": "f9fe4c75-cf94-46e3-e5d3-3a949b485ae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 1\n",
      "Bucket 2\n",
      "Bucket 3\n",
      "Bucket 4\n",
      "Bucket 5\n",
      "Bucket 6\n",
      "Bucket 7\n",
      "Bucket 8\n",
      "Bucket 9\n",
      "Bucket 10\n",
      "Bucket 11\n",
      "Bucket 12\n",
      "Bucket 13\n",
      "Bucket 14\n",
      "Bucket 15\n",
      "Bucket 16\n",
      "Bucket 17\n",
      "Bucket 18\n",
      "Bucket 19\n",
      "Bucket 20\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "\n",
    "    dataset_manager = DatasetManager(dataset_name)\n",
    "\n",
    "    for ii in range(n_iter):\n",
    "        num_buckets = len([name for name in os.listdir(os.path.join(PATH,'%s/%s_%s/models'% (dataset_ref, cls_method, method_name)))])\n",
    "        \n",
    "        if num_buckets < max_prefix:\n",
    "            max_prefix = num_buckets\n",
    "        \n",
    "        buckets = range(0, max_prefix, gap)\n",
    "\n",
    "        for bucket in buckets:\n",
    "            bucketID = bucket+1\n",
    "            print ('Bucket', bucketID)\n",
    "\n",
    "            #import everything needed to sort and predict\n",
    "            #feat_comb_path = os.path.join(PATH, \"%s/%s_%s/bucketers_and_encoders/feature_combiner_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            #cls_path = os.path.join(PATH, \"%s/%s_%s/models/cls_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            #cls = load_model(cls_path)\n",
    "            #feature_combiner = joblib.load(feat_comb_path)\n",
    "\n",
    "            #import previously identified samples\n",
    "            tn_path = os.path.join(PATH, \"%s/%s_%s/samples/true_neg_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            tp_path = os.path.join(PATH, \"%s/%s_%s/samples/true_pos_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            fn_path = os.path.join(PATH, \"%s/%s_%s/samples/false_neg_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "            fp_path = os.path.join(PATH, \"%s/%s_%s/samples/false_pos_bucket_%s_.pickle\" % (dataset_ref, cls_method, method_name, bucketID))\n",
    "\n",
    "            sample_instances = []\n",
    "\n",
    "            with open (tn_path, 'rb') as f:\n",
    "                tn_list = pickle.load(f)\n",
    "            with open (tp_path, 'rb') as f:\n",
    "                tp_list = pickle.load(f)\n",
    "            with open (fn_path, 'rb') as f:\n",
    "                fn_list = pickle.load(f)\n",
    "            with open (fp_path, 'rb') as f:\n",
    "                fp_list = pickle.load(f)\n",
    "\n",
    "            #save results to a list\n",
    "            sample_instances.append(tn_list)\n",
    "            sample_instances.append(tp_list)\n",
    "            sample_instances.append(fn_list)\n",
    "            sample_instances.append(fp_list)\n",
    "            \n",
    "            \n",
    "            for lis in sample_instances:\n",
    "                for each in lis:\n",
    "                    dispersal_lime = each['lime_weights_dispersal']\n",
    "                    dispersal_shap = each['shap_weights_dispersal']\n",
    "                    adj_dispersal_lime = each['adjusted_lime_weights_dispersal']\n",
    "                    adj_dispersal_shap = each['adjusted_shap_weights_dispersal']\n",
    "                    \n",
    "                    lime_stability = 1-np.mean(dispersal_lime)\n",
    "                    shap_stability = 1-np.mean(dispersal_shap)\n",
    "                    adj_lime_stability = 1-np.mean(adj_dispersal_lime)\n",
    "                    adj_shap_stability = 1-np.mean(adj_dispersal_shap)\n",
    "                    \n",
    "                    each['lime_importance_stability'] = lime_stability\n",
    "                    each['shap_importance_stability'] = shap_stability\n",
    "                    each['adjusted_lime_importance_stability'] = adj_lime_stability\n",
    "                    each['adjusted_shap_importance_stability'] = adj_shap_stability\n",
    "\n",
    "            with open (tn_path, 'wb') as f:\n",
    "                pickle.dump(sample_instances[0], f)\n",
    "            with open (tp_path, 'wb') as f:\n",
    "                pickle.dump(sample_instances[1], f)\n",
    "            with open (fn_path, 'wb') as f:\n",
    "                pickle.dump(sample_instances[2], f)\n",
    "            with open (fp_path, 'wb') as f:\n",
    "                pickle.dump(sample_instances[3], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['caseID', 'input', 'actual', 'predicted', 'proba', 'nr_events', 'pred_type', 'shap_fid_change', 'lime_fid_change', 'lime_stability', 'lime_weights_dispersal', 'adjusted_lime_weights_dispersal', 'tree_shap_stability', 'shap_weights_dispersal', 'adjusted_shap_weights_dispersal', 'lime_importance_stability', 'shap_importance_stability', 'adjusted_lime_importance_stability', 'adjusted_shap_importance_stability'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each.keys()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bpic2012_update_dict.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
