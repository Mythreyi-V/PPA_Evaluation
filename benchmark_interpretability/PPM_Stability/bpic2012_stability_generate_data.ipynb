{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"bpic2012_stability_generate_data.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TNrzy43BSk0S","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import sys\n","sys.path.append('/content/drive/My Drive/PPM_Stability/')\n","PATH = '/content/drive/My Drive/PPM_Stability/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OH7t3uEIU6e0","colab_type":"code","colab":{}},"source":["!pip install pandas==0.22.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5sny80CkSAnW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597642324388,"user_tz":-600,"elapsed":5773,"user":{"displayName":"Mythreyi Velmurugan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6DP4Hn-qpp593Bc6lrayXXcdQv42KAS3zJ-Ay=s64","userId":"09509504425224260690"}}},"source":["import EncoderFactory\n","from DatasetManager_for_colab import DatasetManager\n","import BucketFactory\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.metrics import roc_auc_score\n","from sklearn.pipeline import FeatureUnion, Pipeline\n","from sklearn.preprocessing import StandardScaler\n","\n","import time\n","import os\n","import sys\n","from sys import argv\n","import pickle\n","from collections import defaultdict\n","\n","from sklearn.ensemble import RandomForestClassifier\n","import xgboost as xgb\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","\n","#import lime\n","#import lime.lime_tabular\n","#from lime import submodular_pick;\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import joblib"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"g32E_o5LSAne","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597642324389,"user_tz":-600,"elapsed":5770,"user":{"displayName":"Mythreyi Velmurugan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6DP4Hn-qpp593Bc6lrayXXcdQv42KAS3zJ-Ay=s64","userId":"09509504425224260690"}},"outputId":"99adc062-d7f9-44c5-d503-77105f69836c"},"source":["dataset_ref = \"bpic2012\"\n","params_dir = PATH + \"params\"\n","results_dir = \"results\"\n","bucket_method = \"single\"\n","cls_encoding = \"agg\"\n","cls_method = \"xgboost\"\n","gap = 1\n","n_iter = 1\n","\n","if bucket_method == \"state\":\n","    bucket_encoding = \"last\"\n","else:\n","    bucket_encoding = \"agg\"\n","\n","method_name = \"%s_%s\"%(bucket_method, cls_encoding)\n","\n","dataset_ref_to_datasets = {\n","    #\"bpic2011\": [\"bpic2011_f%s\"%formula for formula in range(1,5)],\n","    \"bpic2015\": [\"bpic2015_%s_f2\"%(municipality) for municipality in range(5,6)],\n","    \"bpic2017\" : [\"bpic2017_accepted\"],\n","    \"bpic2012\" : [\"bpic2012_accepted\"]\n","    #\"insurance\": [\"insurance_activity\", \"insurance_followup\"],\n","    #\"sepsis_cases\": [\"sepsis_cases_1\", \"sepsis_cases_2\", \"sepsis_cases_4\"]\n","}\n","\n","encoding_dict = {\n","    \"laststate\": [\"static\", \"last\"],\n","    \"agg\": [\"static\", \"agg\"],\n","    \"index\": [\"static\", \"index\"],\n","    \"combined\": [\"static\", \"last\", \"agg\"]\n","}\n","\n","datasets = [dataset_ref] if dataset_ref not in dataset_ref_to_datasets else dataset_ref_to_datasets[dataset_ref]\n","methods = encoding_dict[cls_encoding]\n","    \n","train_ratio = 0.8\n","random_state = 22\n","\n","# create results directory\n","if not os.path.exists(os.path.join(params_dir)):\n","    os.makedirs(os.path.join(params_dir))\n","    \n","print(datasets)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["['bpic2012_accepted']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O5tFTI_cSAnn","colab_type":"code","colab":{}},"source":["for dataset_name in datasets:\n","    \n","    # load optimal params\n","    print(\"Setting up parameters...\")\n","    optimal_params_filename = os.path.join(params_dir, \"optimal_params_%s_%s_%s.pickle\" % (cls_method, dataset_name, method_name))\n","\n","    if not os.path.isfile(optimal_params_filename) or os.path.getsize(optimal_params_filename) <= 0:\n","        continue\n","        \n","    with open(optimal_params_filename, \"rb\") as fin:\n","        args = pickle.load(fin)\n","            \n","    # read the data\n","    print(\"setting up data...\")\n","    dataset_manager = DatasetManager(dataset_name)\n","    data = dataset_manager.read_dataset()\n","    cls_encoder_args = {'case_id_col': dataset_manager.case_id_col, \n","                        'static_cat_cols': dataset_manager.static_cat_cols,\n","                        'static_num_cols': dataset_manager.static_num_cols, \n","                        'dynamic_cat_cols': dataset_manager.dynamic_cat_cols,\n","                        'dynamic_num_cols': dataset_manager.dynamic_num_cols, \n","                        'fillna': True}\n","\n","    # determine min and max (truncated) prefix lengths\n","    min_prefix_length = 1\n","    if \"traffic_fines\" in dataset_name:\n","        max_prefix_length = 10\n","    elif \"bpic2017\" in dataset_name:\n","        max_prefix_length = min(20, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n","    else:\n","        max_prefix_length = min(40, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n","\n","    # split into training and test\n","    train, test = dataset_manager.split_data_strict(data, train_ratio, split=\"temporal\")\n","    \n","    if gap > 1:\n","        outfile = os.path.join(results_dir, \"performance_results_%s_%s_%s_gap%s.csv\" % (cls_method, dataset_name, method_name, gap))\n","    else:\n","        outfile = os.path.join(results_dir, \"performance_results_%s_%s_%s.csv\" % (cls_method, dataset_name, method_name))\n","        \n","    start_test_prefix_generation = time.time()\n","    dt_test_prefixes = dataset_manager.generate_prefix_data(test, min_prefix_length, max_prefix_length)\n","    test_prefix_generation_time = time.time() - start_test_prefix_generation\n","            \n","    offline_total_times = []\n","    online_event_times = []\n","    train_prefix_generation_times = []\n","\n","    for ii in range(n_iter):\n","        # create prefix logs\n","        print(\"Creating logs...\")\n","        start_train_prefix_generation = time.time()\n","        dt_train_prefixes = dataset_manager.generate_prefix_data(train, min_prefix_length, max_prefix_length, gap)\n","        train_prefix_generation_time = time.time() - start_train_prefix_generation\n","        train_prefix_generation_times.append(train_prefix_generation_time)\n","            \n","        # Bucketing prefixes based on control flow\n","        print(\"bucketing prefixes...\")\n","        bucketer_args = {'encoding_method':bucket_encoding, \n","                         'case_id_col':dataset_manager.case_id_col, \n","                         'cat_cols':[dataset_manager.activity_col], \n","                         'num_cols':[], \n","                         'random_state':random_state}\n","        if bucket_method == \"cluster\":\n","            bucketer_args[\"n_clusters\"] = int(args[\"n_clusters\"])\n","        bucketer = BucketFactory.get_bucketer(bucket_method, **bucketer_args)\n","\n","        start_offline_time_bucket = time.time()\n","        bucket_assignments_train = bucketer.fit_predict(dt_train_prefixes)\n","        offline_time_bucket = time.time() - start_offline_time_bucket\n","\n","        bucket_assignments_test = bucketer.predict(dt_test_prefixes)\n","\n","        preds_all = []\n","        test_y_all = []\n","        nr_events_all = []\n","        offline_time_fit = 0\n","        current_online_event_times = []\n","        \n","        for bucket in set(bucket_assignments_test):\n","            print(\"Bucket\" , bucket )\n","            print(\"sorting bucket...\")\n","            if bucket_method == \"prefix\":\n","                current_args = args[bucket]\n","            else:\n","                current_args = args\n","            relevant_train_cases_bucket = dataset_manager.get_indexes(dt_train_prefixes)[bucket_assignments_train == bucket]\n","            relevant_test_cases_bucket = dataset_manager.get_indexes(dt_test_prefixes)[bucket_assignments_test == bucket]\n","            dt_test_bucket = dataset_manager.get_relevant_data_by_indexes(dt_test_prefixes, relevant_test_cases_bucket)\n","            \n","            nr_events_all.extend(list(dataset_manager.get_prefix_lengths(dt_test_bucket)))\n","            print('number events', len(nr_events_all))\n","            \n","            if len(relevant_train_cases_bucket) == 0:\n","                preds = [dataset_manager.get_class_ratio(train)] * len(relevant_test_cases_bucket)\n","                current_online_event_times.extend([0] * len(preds))\n","            else:\n","                dt_train_bucket = dataset_manager.get_relevant_data_by_indexes(dt_train_prefixes, relevant_train_cases_bucket) # one row per event\n","                train_y = dataset_manager.get_label_numeric(dt_train_bucket)\n","\n","                if len(set(train_y)) < 2:\n","                    preds = [train_y[0]] * len(relevant_test_cases_bucket)\n","                    current_online_event_times.extend([0] * len(preds))\n","                    test_y_all.extend(dataset_manager.get_label_numeric(dt_test_bucket))\n","                else:\n","                    print(\"choosing classifier...\")\n","                    start_offline_time_fit = time.time()\n","                    feature_combiner = FeatureUnion([(method, EncoderFactory.get_encoder(method, **cls_encoder_args)) for method in methods])\n","\n","                    if cls_method == \"rf\":\n","                        cls = RandomForestClassifier(n_estimators=500,\n","                                                     max_features=current_args['max_features'],\n","                                                     random_state=random_state)\n","\n","                    elif cls_method == \"xgboost\":\n","                        cls = xgb.XGBClassifier(objective='binary:logistic',\n","                                                n_estimators=500,\n","                                                learning_rate= current_args['learning_rate'],\n","                                                subsample=current_args['subsample'],\n","                                                max_depth=int(current_args['max_depth']),\n","                                                colsample_bytree=current_args['colsample_bytree'],\n","                                                min_child_weight=int(current_args['min_child_weight']),\n","                                                seed=random_state)\n","\n","                    elif cls_method == \"logit\":\n","                        cls = LogisticRegression(C=2**current_args['C'],\n","                                                 random_state=random_state)\n","\n","                    elif cls_method == \"svm\":\n","                        cls = SVC(C=2**current_args['C'],\n","                                  gamma=2**current_args['gamma'],\n","                                  random_state=random_state)\n","\n","                    if cls_method == \"svm\" or cls_method == \"logit\":\n","                        pipeline = Pipeline([('encoder', feature_combiner), ('scaler', StandardScaler()), ('cls', cls)])\n","                    else:\n","                        pipeline = Pipeline([('encoder', feature_combiner), ('cls', cls)])\n","\n","                    print(\"fitting pipeline...\")\n","                    pipeline.fit(dt_train_bucket, train_y)\n","                    \n","                    offline_time_fit += time.time() - start_offline_time_fit\n","\n","                    # predict separately for each prefix case\n","                    preds = []\n","                    \n","                    test_all_grouped = dt_test_bucket.groupby(dataset_manager.case_id_col)\n","                    print(\"test data shape\", dt_test_bucket.shape)\n","                    count_d=0 # count for deviant\n","                    count_r=0 #count for regular\n","                    for _, group in test_all_grouped:\n","                        print(\"testing new group...\")\n","                        test_y_group = dataset_manager.get_label_numeric(group)\n","                        test_y_all.extend(test_y_group)\n","                            \n","                        start = time.time()\n","                        _ = bucketer.predict(group)\n","                        \n","                        if cls_method == \"svm\":\n","                            pred = pipeline.decision_function(group)\n","                        else:\n","                            preds_pos_label_idx = np.where(cls.classes_ == 1)[0][0]\n","                            pred = pipeline.predict_proba(group)[:,preds_pos_label_idx]\n","                        pipeline_pred_time = time.time() - start\n","                        current_online_event_times.append(pipeline_pred_time / len(group))\n","                        preds.extend(pred)\n","                        \n","\n","            preds_all.extend(preds)\n","\n","            #Save models\n","            print(\"saving models...\")\n","            pipeline_path = os.path.join(PATH, \"%s/pipelines/pipeline_%s_%s_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucket))\n","            feat_comb_path = os.path.join(PATH, \"%s/bucketers_and_encoders/feature_combiner_%s_%s_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucket))\n","            bucketer_path = os.path.join(PATH, \"%s/bucketers_and_encoders/bucketer_%s_%s_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucket))\n","            cls_path = os.path.join(PATH, \"%s/models/cls_%s_%s_bucket_%s.joblib\" % (dataset_ref, cls_method, method_name, bucket))\n","            joblib.dump(pipeline, pipeline_path)\n","            joblib.dump(feature_combiner, feat_comb_path)\n","            joblib.dump(cls, cls_path)\n","            joblib.dump(bucketer, bucketer_path)\n","\n","            #Save training data\n","            print(\"saving data...\")\n","            X_train_path = os.path.join(PATH, \"%s/train_data/%s_%s_bucket_%s_prefixes.pickle\" % (dataset_ref, cls_method, method_name, bucket))\n","            Y_train_path = os.path.join(PATH, \"%s/train_data/%s_%s_bucket_%s_labels.pickle\" % (dataset_ref, cls_method, method_name, bucket))\n","            with open(X_train_path, 'wb') as f:\n","              pickle.dump(dt_train_bucket, f)\n","            with open(Y_train_path, 'wb') as f:\n","              pickle.dump(train_y, f)\n","\n","            #Save testing data\n","            X_test_path = os.path.join(PATH, \"%s/test_data/%s_%s_bucket_%s_prefixes.pickle\" % (dataset_ref, cls_method, method_name, bucket))\n","            Y_test_path = os.path.join(PATH, \"%s/test_data/%s_%s_bucket_%s_labels.pickle\" % (dataset_ref, cls_method, method_name, bucket))\n","            with open(X_test_path, 'wb') as f:\n","                pickle.dump(dt_test_bucket, f)\n","            with open(Y_test_path, 'wb') as f:\n","                pickle.dump(test_y_group, f)\n","        \n","        print(\"compiling results...\")\n","        dt_results = pd.DataFrame({\"actual\": test_y_all, \"predicted\": preds_all, \"nr_events\": nr_events_all})\n","        for nr_events, group in dt_results.groupby(\"nr_events\"):\n","            if len(set(group.actual)) < 2:\n","                print(dataset_name, method_name, cls_method, nr_events, \"auc\", np.nan)\n","            else:\n","                print(dataset_name, method_name, cls_method, nr_events, \"auc\", roc_auc_score(group.actual, group.predicted))\n","        print(dataset_name, method_name, cls_method, -1, -1, \"auc\", roc_auc_score(dt_results.actual, dt_results.predicted))\n"],"execution_count":null,"outputs":[]}]}