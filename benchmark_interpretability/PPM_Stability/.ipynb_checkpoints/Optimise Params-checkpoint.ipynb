{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bpic2012_accepted']\n",
      "splitting data\n",
      "single                                                                                                                 \n",
      "0:\tlearn: 0.6522052\ttotal: 1.97s\tremaining: 32m 48s                                                                    \n",
      "\n",
      "1:\tlearn: 0.6143198\ttotal: 3.91s\tremaining: 32m 32s                                                                    \n",
      "\n",
      "2:\tlearn: 0.5721330\ttotal: 5.72s\tremaining: 31m 40s                                                                    \n",
      "\n",
      "3:\tlearn: 0.5148231\ttotal: 7.47s\tremaining: 31m                                                                        \n",
      "\n",
      "4:\tlearn: 0.4957643\ttotal: 9.16s\tremaining: 30m 23s                                                                    \n",
      "\n",
      "5:\tlearn: 0.4667501\ttotal: 10.9s\tremaining: 30m 2s                                                                     \n",
      "\n",
      "6:\tlearn: 0.4500314\ttotal: 12.6s\tremaining: 29m 47s                                                                    \n",
      "\n",
      "7:\tlearn: 0.4202107\ttotal: 14.3s\tremaining: 29m 32s                                                                    \n",
      "\n",
      "8:\tlearn: 0.4063287\ttotal: 16s\tremaining: 29m 17s                                                                      \n",
      "\n",
      "9:\tlearn: 0.3799641\ttotal: 17.6s\tremaining: 28m 59s                                                                    \n",
      "\n",
      "10:\tlearn: 0.3655399\ttotal: 19.2s\tremaining: 28m 46s                                                                   \n",
      "\n",
      "11:\tlearn: 0.3520136\ttotal: 20.8s\tremaining: 28m 33s                                                                   \n",
      "\n",
      "12:\tlearn: 0.3406534\ttotal: 22.4s\tremaining: 28m 18s                                                                   \n",
      "\n",
      "13:\tlearn: 0.3274901\ttotal: 24s\tremaining: 28m 8s                                                                      \n",
      "\n",
      "14:\tlearn: 0.3141375\ttotal: 25.6s\tremaining: 27m 58s                                                                   \n",
      "\n",
      "15:\tlearn: 0.3072871\ttotal: 27.2s\tremaining: 27m 50s                                                                   \n",
      "\n",
      "16:\tlearn: 0.2977443\ttotal: 28.7s\tremaining: 27m 41s                                                                   \n",
      "\n",
      "17:\tlearn: 0.2904455\ttotal: 30.4s\tremaining: 27m 36s                                                                   \n",
      "\n",
      "18:\tlearn: 0.2756698\ttotal: 32s\tremaining: 27m 30s                                                                     \n",
      "\n",
      "19:\tlearn: 0.2669150\ttotal: 33.6s\tremaining: 27m 24s                                                                   \n",
      "\n",
      "20:\tlearn: 0.2633070\ttotal: 35.2s\tremaining: 27m 19s                                                                   \n",
      "\n",
      "21:\tlearn: 0.2591969\ttotal: 36.7s\tremaining: 27m 13s                                                                   \n",
      "\n",
      "22:\tlearn: 0.2542688\ttotal: 38.3s\tremaining: 27m 7s                                                                    \n",
      "\n",
      "23:\tlearn: 0.2481653\ttotal: 39.9s\tremaining: 27m 3s                                                                    \n",
      "\n",
      "24:\tlearn: 0.2438804\ttotal: 41.5s\tremaining: 26m 58s                                                                   \n",
      "\n",
      "25:\tlearn: 0.2386897\ttotal: 43.1s\tremaining: 26m 53s                                                                   \n",
      "\n",
      "26:\tlearn: 0.2303978\ttotal: 44.7s\tremaining: 26m 49s                                                                   \n",
      "\n",
      "27:\tlearn: 0.2264937\ttotal: 46.2s\tremaining: 26m 45s                                                                   \n",
      "\n",
      "28:\tlearn: 0.2244696\ttotal: 47.8s\tremaining: 26m 41s                                                                   \n",
      "\n",
      "29:\tlearn: 0.2229302\ttotal: 49.4s\tremaining: 26m 37s                                                                   \n",
      "\n",
      "30:\tlearn: 0.2176940\ttotal: 51s\tremaining: 26m 34s                                                                     \n",
      "\n",
      "31:\tlearn: 0.2144243\ttotal: 52.6s\tremaining: 26m 31s                                                                   \n",
      "\n",
      "32:\tlearn: 0.2123748\ttotal: 54.2s\tremaining: 26m 27s                                                                   \n",
      "\n",
      "33:\tlearn: 0.2092796\ttotal: 55.8s\tremaining: 26m 24s                                                                   \n",
      "\n",
      "34:\tlearn: 0.2007788\ttotal: 57.4s\tremaining: 26m 21s                                                                   \n",
      "\n",
      "35:\tlearn: 0.1941885\ttotal: 58.9s\tremaining: 26m 18s                                                                   \n",
      "\n",
      "36:\tlearn: 0.1904762\ttotal: 1m\tremaining: 26m 14s                                                                      \n",
      "\n",
      "37:\tlearn: 0.1889190\ttotal: 1m 2s\tremaining: 26m 12s                                                                   \n",
      "\n",
      "38:\tlearn: 0.1816575\ttotal: 1m 3s\tremaining: 26m 8s                                                                    \n",
      "\n",
      "39:\tlearn: 0.1771871\ttotal: 1m 5s\tremaining: 26m 6s                                                                    \n",
      "\n",
      "40:\tlearn: 0.1710048\ttotal: 1m 6s\tremaining: 26m 3s                                                                    \n",
      "\n",
      "41:\tlearn: 0.1687384\ttotal: 1m 8s\tremaining: 26m                                                                       \n",
      "\n",
      "42:\tlearn: 0.1665204\ttotal: 1m 10s\tremaining: 25m 58s                                                                  \n",
      "\n",
      "43:\tlearn: 0.1627312\ttotal: 1m 11s\tremaining: 25m 56s                                                                  \n",
      "\n",
      "44:\tlearn: 0.1598037\ttotal: 1m 13s\tremaining: 25m 54s                                                                  \n",
      "\n",
      "45:\tlearn: 0.1587775\ttotal: 1m 14s\tremaining: 25m 51s                                                                  \n",
      "\n",
      "46:\tlearn: 0.1572519\ttotal: 1m 16s\tremaining: 25m 49s                                                                  \n",
      "\n",
      "47:\tlearn: 0.1543325\ttotal: 1m 18s\tremaining: 25m 47s                                                                  \n",
      "\n",
      "48:\tlearn: 0.1499061\ttotal: 1m 19s\tremaining: 25m 46s                                                                  \n",
      "\n",
      "49:\tlearn: 0.1480068\ttotal: 1m 21s\tremaining: 25m 43s                                                                  \n",
      "\n",
      "50:\tlearn: 0.1441126\ttotal: 1m 22s\tremaining: 25m 41s                                                                  \n",
      "\n",
      "51:\tlearn: 0.1415853\ttotal: 1m 24s\tremaining: 25m 39s                                                                  \n",
      "\n",
      "52:\tlearn: 0.1384675\ttotal: 1m 26s\tremaining: 25m 37s                                                                  \n",
      "\n",
      "53:\tlearn: 0.1363484\ttotal: 1m 27s\tremaining: 25m 34s                                                                  \n",
      "\n",
      "54:\tlearn: 0.1330741\ttotal: 1m 29s\tremaining: 25m 33s                                                                  \n",
      "\n",
      "55:\tlearn: 0.1313221\ttotal: 1m 30s\tremaining: 25m 30s                                                                  \n",
      "\n",
      "56:\tlearn: 0.1279786\ttotal: 1m 32s\tremaining: 25m 29s                                                                  \n",
      "\n",
      "57:\tlearn: 0.1248733\ttotal: 1m 34s\tremaining: 25m 27s                                                                  \n",
      "\n",
      "58:\tlearn: 0.1226459\ttotal: 1m 35s\tremaining: 25m 25s                                                                  \n",
      "\n",
      "59:\tlearn: 0.1211861\ttotal: 1m 37s\tremaining: 25m 23s                                                                  \n",
      "\n",
      "60:\tlearn: 0.1197604\ttotal: 1m 38s\tremaining: 25m 21s                                                                  \n",
      "\n",
      "61:\tlearn: 0.1176944\ttotal: 1m 40s\tremaining: 25m 20s                                                                  \n",
      "\n",
      "62:\tlearn: 0.1153050\ttotal: 1m 42s\tremaining: 25m 18s                                                                  \n",
      "\n",
      "63:\tlearn: 0.1121477\ttotal: 1m 43s\tremaining: 25m 16s                                                                  \n",
      "\n",
      "64:\tlearn: 0.1083555\ttotal: 1m 45s\tremaining: 25m 14s                                                                  \n",
      "\n",
      "65:\tlearn: 0.1066790\ttotal: 1m 46s\tremaining: 25m 12s                                                                  \n",
      "\n",
      "66:\tlearn: 0.1046561\ttotal: 1m 48s\tremaining: 25m 9s                                                                   \n",
      "\n",
      "67:\tlearn: 0.1033255\ttotal: 1m 49s\tremaining: 25m 7s                                                                   \n",
      "\n",
      "68:\tlearn: 0.1010555\ttotal: 1m 51s\tremaining: 25m 6s                                                                   \n",
      "\n",
      "69:\tlearn: 0.0982049\ttotal: 1m 53s\tremaining: 25m 4s                                                                   \n",
      "\n",
      "70:\tlearn: 0.0963218\ttotal: 1m 54s\tremaining: 25m 2s                                                                   \n",
      "\n",
      "71:\tlearn: 0.0948811\ttotal: 1m 56s\tremaining: 25m                                                                      \n",
      "\n",
      "72:\tlearn: 0.0930554\ttotal: 1m 58s\tremaining: 24m 58s                                                                  \n",
      "\n",
      "73:\tlearn: 0.0907930\ttotal: 1m 59s\tremaining: 24m 56s                                                                  \n",
      "\n",
      "74:\tlearn: 0.0894536\ttotal: 2m 1s\tremaining: 24m 55s                                                                   \n",
      "\n",
      "75:\tlearn: 0.0871951\ttotal: 2m 2s\tremaining: 24m 53s                                                                   \n",
      "\n",
      "76:\tlearn: 0.0849791\ttotal: 2m 4s\tremaining: 24m 52s                                                                   \n",
      "\n",
      "77:\tlearn: 0.0838373\ttotal: 2m 6s\tremaining: 24m 51s                                                                   \n",
      "\n",
      "78:\tlearn: 0.0825930\ttotal: 2m 7s\tremaining: 24m 49s                                                                   \n",
      "\n",
      "79:\tlearn: 0.0804703\ttotal: 2m 9s\tremaining: 24m 47s                                                                   \n",
      "\n",
      "80:\tlearn: 0.0791855\ttotal: 2m 11s\tremaining: 24m 46s                                                                  \n",
      "\n",
      "81:\tlearn: 0.0778145\ttotal: 2m 12s\tremaining: 24m 44s                                                                  \n",
      "\n",
      "82:\tlearn: 0.0758844\ttotal: 2m 14s\tremaining: 24m 43s                                                                  \n",
      "\n",
      "83:\tlearn: 0.0745237\ttotal: 2m 15s\tremaining: 24m 41s                                                                  \n",
      "\n",
      "84:\tlearn: 0.0734717\ttotal: 2m 17s\tremaining: 24m 40s                                                                  \n",
      "\n",
      "85:\tlearn: 0.0724597\ttotal: 2m 19s\tremaining: 24m 39s                                                                  \n",
      "\n",
      "86:\tlearn: 0.0717305\ttotal: 2m 20s\tremaining: 24m 38s                                                                  \n",
      "\n",
      "87:\tlearn: 0.0706682\ttotal: 2m 22s\tremaining: 24m 36s                                                                  \n",
      "\n",
      "88:\tlearn: 0.0698886\ttotal: 2m 24s\tremaining: 24m 35s                                                                  \n",
      "\n",
      "89:\tlearn: 0.0686149\ttotal: 2m 25s\tremaining: 24m 34s                                                                  \n",
      "\n",
      "90:\tlearn: 0.0678341\ttotal: 2m 27s\tremaining: 24m 32s                                                                  \n",
      "\n",
      "91:\tlearn: 0.0670465\ttotal: 2m 29s\tremaining: 24m 31s                                                                  \n",
      "\n",
      "92:\tlearn: 0.0661652\ttotal: 2m 30s\tremaining: 24m 29s                                                                  \n",
      "\n",
      "93:\tlearn: 0.0655540\ttotal: 2m 32s\tremaining: 24m 28s                                                                  \n",
      "\n",
      "94:\tlearn: 0.0650637\ttotal: 2m 34s\tremaining: 24m 27s                                                                  \n",
      "\n",
      "95:\tlearn: 0.0639073\ttotal: 2m 35s\tremaining: 24m 25s                                                                  \n",
      "\n",
      "96:\tlearn: 0.0629591\ttotal: 2m 37s\tremaining: 24m 24s                                                                  \n",
      "\n",
      "97:\tlearn: 0.0620239\ttotal: 2m 38s\tremaining: 24m 22s                                                                  \n",
      "\n",
      "98:\tlearn: 0.0614933\ttotal: 2m 40s\tremaining: 24m 21s                                                                  \n",
      "\n",
      "99:\tlearn: 0.0604098\ttotal: 2m 42s\tremaining: 24m 19s                                                                  \n",
      "\n",
      "100:\tlearn: 0.0593168\ttotal: 2m 43s\tremaining: 24m 18s                                                                 \n",
      "\n",
      "101:\tlearn: 0.0589058\ttotal: 2m 45s\tremaining: 24m 17s                                                                 \n",
      "\n",
      "102:\tlearn: 0.0581350\ttotal: 2m 47s\tremaining: 24m 15s                                                                 \n",
      "\n",
      "103:\tlearn: 0.0573832\ttotal: 2m 48s\tremaining: 24m 14s                                                                 \n",
      "\n",
      "104:\tlearn: 0.0566150\ttotal: 2m 50s\tremaining: 24m 12s                                                                 \n",
      "\n",
      "105:\tlearn: 0.0559228\ttotal: 2m 52s\tremaining: 24m 11s                                                                 \n",
      "\n",
      "106:\tlearn: 0.0546790\ttotal: 2m 53s\tremaining: 24m 9s                                                                  \n",
      "\n",
      "107:\tlearn: 0.0538627\ttotal: 2m 55s\tremaining: 24m 8s                                                                  \n",
      "\n",
      "108:\tlearn: 0.0528736\ttotal: 2m 56s\tremaining: 24m 6s                                                                  \n",
      "\n",
      "109:\tlearn: 0.0522762\ttotal: 2m 58s\tremaining: 24m 4s                                                                  \n",
      "\n",
      "110:\tlearn: 0.0518093\ttotal: 3m\tremaining: 24m 3s                                                                      \n",
      "\n",
      "111:\tlearn: 0.0510224\ttotal: 3m 1s\tremaining: 24m 2s                                                                   \n",
      "\n",
      "112:\tlearn: 0.0502641\ttotal: 3m 3s\tremaining: 24m                                                                      \n",
      "\n",
      "113:\tlearn: 0.0492976\ttotal: 3m 5s\tremaining: 23m 59s                                                                  \n",
      "\n",
      "114:\tlearn: 0.0488404\ttotal: 3m 6s\tremaining: 23m 58s                                                                  \n",
      "\n",
      "115:\tlearn: 0.0483767\ttotal: 3m 8s\tremaining: 23m 56s                                                                  \n",
      "\n",
      "116:\tlearn: 0.0475519\ttotal: 3m 10s\tremaining: 23m 55s                                                                 \n",
      "\n",
      "117:\tlearn: 0.0471464\ttotal: 3m 11s\tremaining: 23m 54s                                                                 \n",
      "\n",
      "118:\tlearn: 0.0466594\ttotal: 3m 13s\tremaining: 23m 52s                                                                 \n",
      "\n",
      "119:\tlearn: 0.0459959\ttotal: 3m 15s\tremaining: 23m 51s                                                                 \n",
      "\n",
      "120:\tlearn: 0.0452672\ttotal: 3m 16s\tremaining: 23m 49s                                                                 \n",
      "\n",
      "121:\tlearn: 0.0448600\ttotal: 3m 18s\tremaining: 23m 48s                                                                 \n",
      "\n",
      "122:\tlearn: 0.0440384\ttotal: 3m 20s\tremaining: 23m 46s                                                                 \n",
      "\n",
      "123:\tlearn: 0.0432308\ttotal: 3m 21s\tremaining: 23m 45s                                                                 \n",
      "\n",
      "124:\tlearn: 0.0427090\ttotal: 3m 23s\tremaining: 23m 43s                                                                 \n",
      "\n",
      "125:\tlearn: 0.0421755\ttotal: 3m 25s\tremaining: 23m 42s                                                                 \n",
      "\n",
      "126:\tlearn: 0.0418814\ttotal: 3m 26s\tremaining: 23m 40s                                                                 \n",
      "\n",
      "127:\tlearn: 0.0411572\ttotal: 3m 28s\tremaining: 23m 39s                                                                 \n",
      "\n",
      "128:\tlearn: 0.0406030\ttotal: 3m 30s\tremaining: 23m 38s                                                                 \n",
      "\n",
      "129:\tlearn: 0.0402901\ttotal: 3m 31s\tremaining: 23m 36s                                                                 \n",
      "\n",
      "130:\tlearn: 0.0400710\ttotal: 3m 33s\tremaining: 23m 35s                                                                 \n",
      "\n",
      "131:\tlearn: 0.0396165\ttotal: 3m 35s\tremaining: 23m 34s                                                                 \n",
      "\n",
      "132:\tlearn: 0.0390695\ttotal: 3m 36s\tremaining: 23m 32s                                                                 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133:\tlearn: 0.0388379\ttotal: 3m 38s\tremaining: 23m 31s                                                                 \n",
      "\n",
      "134:\tlearn: 0.0383393\ttotal: 3m 40s\tremaining: 23m 29s                                                                 \n",
      "\n",
      "135:\tlearn: 0.0376871\ttotal: 3m 41s\tremaining: 23m 28s                                                                 \n",
      "\n",
      "136:\tlearn: 0.0371365\ttotal: 3m 43s\tremaining: 23m 27s                                                                 \n",
      "\n",
      "137:\tlearn: 0.0365475\ttotal: 3m 45s\tremaining: 23m 25s                                                                 \n",
      "\n",
      "138:\tlearn: 0.0360616\ttotal: 3m 46s\tremaining: 23m 24s                                                                 \n",
      "\n",
      "139:\tlearn: 0.0356424\ttotal: 3m 48s\tremaining: 23m 22s                                                                 \n",
      "\n",
      "140:\tlearn: 0.0353557\ttotal: 3m 49s\tremaining: 23m 21s                                                                 \n",
      "\n",
      "141:\tlearn: 0.0348116\ttotal: 3m 51s\tremaining: 23m 19s                                                                 \n",
      "\n",
      "142:\tlearn: 0.0345034\ttotal: 3m 53s\tremaining: 23m 18s                                                                 \n",
      "\n",
      "143:\tlearn: 0.0341433\ttotal: 3m 55s\tremaining: 23m 17s                                                                 \n",
      "\n",
      "144:\tlearn: 0.0340105\ttotal: 3m 56s\tremaining: 23m 15s                                                                 \n",
      "\n",
      "145:\tlearn: 0.0336020\ttotal: 3m 58s\tremaining: 23m 14s                                                                 \n",
      "\n",
      "146:\tlearn: 0.0331385\ttotal: 4m\tremaining: 23m 13s                                                                     \n",
      "\n",
      "147:\tlearn: 0.0325855\ttotal: 4m 1s\tremaining: 23m 11s                                                                  \n",
      "\n",
      "148:\tlearn: 0.0322218\ttotal: 4m 3s\tremaining: 23m 10s                                                                  \n",
      "\n",
      "149:\tlearn: 0.0317906\ttotal: 4m 5s\tremaining: 23m 9s                                                                   \n",
      "\n",
      "150:\tlearn: 0.0314029\ttotal: 4m 6s\tremaining: 23m 7s                                                                   \n",
      "\n",
      "151:\tlearn: 0.0312251\ttotal: 4m 8s\tremaining: 23m 6s                                                                   \n",
      "\n",
      "152:\tlearn: 0.0309290\ttotal: 4m 10s\tremaining: 23m 4s                                                                  \n",
      "\n",
      "153:\tlearn: 0.0306047\ttotal: 4m 11s\tremaining: 23m 3s                                                                  \n",
      "\n",
      "154:\tlearn: 0.0303603\ttotal: 4m 13s\tremaining: 23m 2s                                                                  \n",
      "\n",
      "155:\tlearn: 0.0300268\ttotal: 4m 15s\tremaining: 23m                                                                     \n",
      "\n",
      "156:\tlearn: 0.0297058\ttotal: 4m 16s\tremaining: 22m 59s                                                                 \n",
      "\n",
      "157:\tlearn: 0.0292465\ttotal: 4m 18s\tremaining: 22m 57s                                                                 \n",
      "\n",
      "158:\tlearn: 0.0288496\ttotal: 4m 20s\tremaining: 22m 56s                                                                 \n",
      "\n",
      "159:\tlearn: 0.0286990\ttotal: 4m 21s\tremaining: 22m 54s                                                                 \n",
      "\n",
      "160:\tlearn: 0.0286061\ttotal: 4m 23s\tremaining: 22m 52s                                                                 \n",
      "\n",
      "161:\tlearn: 0.0284294\ttotal: 4m 25s\tremaining: 22m 51s                                                                 \n",
      "\n",
      "162:\tlearn: 0.0281583\ttotal: 4m 26s\tremaining: 22m 49s                                                                 \n",
      "\n",
      "163:\tlearn: 0.0279503\ttotal: 4m 28s\tremaining: 22m 48s                                                                 \n",
      "\n",
      "164:\tlearn: 0.0276841\ttotal: 4m 30s\tremaining: 22m 47s                                                                 \n",
      "\n",
      "165:\tlearn: 0.0274162\ttotal: 4m 31s\tremaining: 22m 45s                                                                 \n",
      "\n",
      "166:\tlearn: 0.0271499\ttotal: 4m 33s\tremaining: 22m 44s                                                                 \n",
      "\n",
      "167:\tlearn: 0.0267708\ttotal: 4m 35s\tremaining: 22m 42s                                                                 \n",
      "\n",
      "168:\tlearn: 0.0264230\ttotal: 4m 36s\tremaining: 22m 41s                                                                 \n",
      "\n",
      "169:\tlearn: 0.0260154\ttotal: 4m 38s\tremaining: 22m 40s                                                                 \n",
      "\n",
      "170:\tlearn: 0.0258307\ttotal: 4m 40s\tremaining: 22m 38s                                                                 \n",
      "\n",
      "171:\tlearn: 0.0256118\ttotal: 4m 41s\tremaining: 22m 37s                                                                 \n",
      "\n",
      "172:\tlearn: 0.0253157\ttotal: 4m 43s\tremaining: 22m 36s                                                                 \n",
      "\n",
      "173:\tlearn: 0.0251570\ttotal: 4m 45s\tremaining: 22m 34s                                                                 \n",
      "\n",
      "174:\tlearn: 0.0249893\ttotal: 4m 47s\tremaining: 22m 33s                                                                 \n",
      "\n",
      "175:\tlearn: 0.0247203\ttotal: 4m 48s\tremaining: 22m 31s                                                                 \n",
      "\n",
      "176:\tlearn: 0.0245957\ttotal: 4m 50s\tremaining: 22m 30s                                                                 \n",
      "\n",
      "177:\tlearn: 0.0243474\ttotal: 4m 52s\tremaining: 22m 28s                                                                 \n",
      "\n",
      "178:\tlearn: 0.0241912\ttotal: 4m 53s\tremaining: 22m 27s                                                                 \n",
      "\n",
      "179:\tlearn: 0.0240659\ttotal: 4m 55s\tremaining: 22m 26s                                                                 \n",
      "\n",
      "180:\tlearn: 0.0238523\ttotal: 4m 57s\tremaining: 22m 24s                                                                 \n",
      "\n",
      "181:\tlearn: 0.0236250\ttotal: 4m 58s\tremaining: 22m 23s                                                                 \n",
      "\n",
      "182:\tlearn: 0.0233075\ttotal: 5m\tremaining: 22m 21s                                                                     \n",
      "\n",
      "183:\tlearn: 0.0232136\ttotal: 5m 2s\tremaining: 22m 19s                                                                  \n",
      "\n",
      "184:\tlearn: 0.0230521\ttotal: 5m 3s\tremaining: 22m 18s                                                                  \n",
      "\n",
      "185:\tlearn: 0.0229451\ttotal: 5m 5s\tremaining: 22m 17s                                                                  \n",
      "\n",
      "186:\tlearn: 0.0227306\ttotal: 5m 7s\tremaining: 22m 15s                                                                  \n",
      "\n",
      "187:\tlearn: 0.0225037\ttotal: 5m 8s\tremaining: 22m 14s                                                                  \n",
      "\n",
      "188:\tlearn: 0.0223349\ttotal: 5m 10s\tremaining: 22m 12s                                                                 \n",
      "\n",
      "189:\tlearn: 0.0220663\ttotal: 5m 12s\tremaining: 22m 11s                                                                 \n",
      "\n",
      "190:\tlearn: 0.0219360\ttotal: 5m 13s\tremaining: 22m 9s                                                                  \n",
      "\n",
      "191:\tlearn: 0.0217986\ttotal: 5m 15s\tremaining: 22m 8s                                                                  \n",
      "\n",
      "192:\tlearn: 0.0217033\ttotal: 5m 17s\tremaining: 22m 7s                                                                  \n",
      "\n",
      "193:\tlearn: 0.0214102\ttotal: 5m 19s\tremaining: 22m 5s                                                                  \n",
      "\n",
      "194:\tlearn: 0.0213048\ttotal: 5m 20s\tremaining: 22m 3s                                                                  \n",
      "\n",
      "195:\tlearn: 0.0211333\ttotal: 5m 22s\tremaining: 22m 2s                                                                  \n",
      "\n",
      "196:\tlearn: 0.0210190\ttotal: 5m 24s\tremaining: 22m 1s                                                                  \n",
      "\n",
      "197:\tlearn: 0.0207629\ttotal: 5m 25s\tremaining: 21m 59s                                                                 \n",
      "\n",
      "198:\tlearn: 0.0206008\ttotal: 5m 27s\tremaining: 21m 58s                                                                 \n",
      "\n",
      "199:\tlearn: 0.0203851\ttotal: 5m 29s\tremaining: 21m 56s                                                                 \n",
      "\n",
      "200:\tlearn: 0.0201453\ttotal: 5m 30s\tremaining: 21m 55s                                                                 \n",
      "\n",
      "201:\tlearn: 0.0199700\ttotal: 5m 32s\tremaining: 21m 54s                                                                 \n",
      "\n",
      "202:\tlearn: 0.0197627\ttotal: 5m 34s\tremaining: 21m 52s                                                                 \n",
      "\n",
      "203:\tlearn: 0.0196566\ttotal: 5m 36s\tremaining: 21m 51s                                                                 \n",
      "\n",
      "204:\tlearn: 0.0193765\ttotal: 5m 37s\tremaining: 21m 50s                                                                 \n",
      "\n",
      "205:\tlearn: 0.0192203\ttotal: 5m 39s\tremaining: 21m 48s                                                                 \n",
      "\n",
      "206:\tlearn: 0.0191177\ttotal: 5m 41s\tremaining: 21m 47s                                                                 \n",
      "\n",
      "207:\tlearn: 0.0189588\ttotal: 5m 42s\tremaining: 21m 45s                                                                 \n",
      "\n",
      "208:\tlearn: 0.0187271\ttotal: 5m 44s\tremaining: 21m 44s                                                                 \n",
      "\n",
      "209:\tlearn: 0.0185985\ttotal: 5m 46s\tremaining: 21m 42s                                                                 \n",
      "\n",
      "210:\tlearn: 0.0185019\ttotal: 5m 48s\tremaining: 21m 41s                                                                 \n",
      "\n",
      "211:\tlearn: 0.0183947\ttotal: 5m 49s\tremaining: 21m 40s                                                                 \n",
      "\n",
      "212:\tlearn: 0.0182651\ttotal: 5m 51s\tremaining: 21m 38s                                                                 \n",
      "\n",
      "213:\tlearn: 0.0181453\ttotal: 5m 53s\tremaining: 21m 37s                                                                 \n",
      "\n",
      "214:\tlearn: 0.0180766\ttotal: 5m 54s\tremaining: 21m 35s                                                                 \n",
      "\n",
      "215:\tlearn: 0.0179942\ttotal: 5m 56s\tremaining: 21m 34s                                                                 \n",
      "\n",
      "216:\tlearn: 0.0178443\ttotal: 5m 58s\tremaining: 21m 32s                                                                 \n",
      "\n",
      "217:\tlearn: 0.0177407\ttotal: 5m 59s\tremaining: 21m 31s                                                                 \n",
      "\n",
      "218:\tlearn: 0.0175932\ttotal: 6m 1s\tremaining: 21m 29s                                                                  \n",
      "\n",
      "219:\tlearn: 0.0174129\ttotal: 6m 3s\tremaining: 21m 28s                                                                  \n",
      "\n",
      "220:\tlearn: 0.0172920\ttotal: 6m 5s\tremaining: 21m 26s                                                                  \n",
      "\n",
      "221:\tlearn: 0.0170865\ttotal: 6m 6s\tremaining: 21m 25s                                                                  \n",
      "\n",
      "222:\tlearn: 0.0169671\ttotal: 6m 8s\tremaining: 21m 23s                                                                  \n",
      "\n",
      "223:\tlearn: 0.0168733\ttotal: 6m 10s\tremaining: 21m 22s                                                                 \n",
      "\n",
      "224:\tlearn: 0.0167757\ttotal: 6m 11s\tremaining: 21m 20s                                                                 \n",
      "\n",
      "225:\tlearn: 0.0167215\ttotal: 6m 13s\tremaining: 21m 19s                                                                 \n",
      "\n",
      "226:\tlearn: 0.0165991\ttotal: 6m 15s\tremaining: 21m 17s                                                                 \n",
      "\n",
      "  0%|                                                                            | 0/3 [06:24<?, ?trial/s, best loss=?]"
     ]
    }
   ],
   "source": [
    "import EncoderFactory\n",
    "from DatasetManager import DatasetManager\n",
    "import BucketFactory\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from sys import argv\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import catboost\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe, fmin, hp\n",
    "import hyperopt\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "\n",
    "def create_and_evaluate_model(args):\n",
    "    global trial_nr\n",
    "    trial_nr += 1\n",
    "    \n",
    "    start = time.time()\n",
    "    score = 0\n",
    "    for cv_iter in range(n_splits):\n",
    "        \n",
    "        dt_test_prefixes = dt_prefixes[cv_iter]\n",
    "        dt_train_prefixes = pd.DataFrame()\n",
    "        for cv_train_iter in range(n_splits): \n",
    "            if cv_train_iter != cv_iter:\n",
    "                dt_train_prefixes = pd.concat([dt_train_prefixes, dt_prefixes[cv_train_iter]], axis=0, sort=False)\n",
    "        \n",
    "        # Bucketing prefixes based on control flow\n",
    "        bucketer_args = {'encoding_method':bucket_encoding, \n",
    "                         'case_id_col':dataset_manager.case_id_col, \n",
    "                         'cat_cols':[dataset_manager.activity_col], \n",
    "                         'num_cols':[], \n",
    "                         'random_state':random_state}\n",
    "        if bucket_method == \"cluster\":\n",
    "            bucketer_args[\"n_clusters\"] = args[\"n_clusters\"]\n",
    "        bucketer = BucketFactory.get_bucketer(bucket_method, **bucketer_args)\n",
    "        bucket_assignments_train = bucketer.fit_predict(dt_train_prefixes)\n",
    "        bucket_assignments_test = bucketer.predict(dt_test_prefixes)\n",
    "        \n",
    "        preds_all = []\n",
    "        test_y_all = []\n",
    "        if \"prefix\" in method_name:\n",
    "            scores = defaultdict(int)\n",
    "        for bucket in set(bucket_assignments_test):\n",
    "            relevant_train_cases_bucket = dataset_manager.get_indexes(dt_train_prefixes)[bucket_assignments_train == bucket]\n",
    "            relevant_test_cases_bucket = dataset_manager.get_indexes(dt_test_prefixes)[bucket_assignments_test == bucket]\n",
    "            dt_test_bucket = dataset_manager.get_relevant_data_by_indexes(dt_test_prefixes, relevant_test_cases_bucket)\n",
    "            test_y = dataset_manager.get_label_numeric(dt_test_bucket)\n",
    "            if len(relevant_train_cases_bucket) == 0:\n",
    "                preds = [class_ratios[cv_iter]] * len(relevant_test_cases_bucket)\n",
    "            else:\n",
    "                dt_train_bucket = dataset_manager.get_relevant_data_by_indexes(dt_train_prefixes, relevant_train_cases_bucket) # one row per event\n",
    "                train_y = dataset_manager.get_label_numeric(dt_train_bucket)\n",
    "                \n",
    "                if len(set(train_y)) < 2:\n",
    "                    preds = [train_y[0]] * len(relevant_test_cases_bucket)\n",
    "                else:\n",
    "                    feature_combiner = FeatureUnion([(method, EncoderFactory.get_encoder(method, **cls_encoder_args)) for method in methods])\n",
    "\n",
    "                    if cls_method == \"rf\":\n",
    "                        cls = RandomForestClassifier(n_estimators=500,\n",
    "                                                     max_features=args['max_features'],\n",
    "                                                     random_state=random_state)\n",
    "\n",
    "                    elif cls_method == \"xgboost\":\n",
    "                        cls = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                                                n_estimators=500,\n",
    "                                                learning_rate= args['learning_rate'],\n",
    "                                                subsample=args['subsample'],\n",
    "                                                max_depth=int(args['max_depth']),\n",
    "                                                colsample_bytree=args['colsample_bytree'],\n",
    "                                                min_child_weight=int(args['min_child_weight']),\n",
    "                                                seed=random_state)\n",
    "                    elif cls_method == \"cb\":\n",
    "                        cls =  catboost.CatBoostClassifier(learning_rate= args['learning_rate'],\n",
    "                                                           subsample=args['subsample'], depth=int(args['depth']))\n",
    "\n",
    "                    elif cls_method == \"logit\":\n",
    "                        cls = LogisticRegression(C=2**args['C'],\n",
    "                                                 random_state=random_state)\n",
    "\n",
    "                    elif cls_method == \"svm\":\n",
    "                        cls = SVC(C=2**args['C'],\n",
    "                                  gamma=2**args['gamma'],\n",
    "                                  random_state=random_state)\n",
    "\n",
    "                    if cls_method == \"svm\" or cls_method == \"logit\":\n",
    "                        pipeline = Pipeline([('encoder', feature_combiner), ('scaler', StandardScaler()), ('cls', cls)])\n",
    "                    else:\n",
    "                        pipeline = Pipeline([('encoder', feature_combiner), ('cls', cls)])\n",
    "                    \n",
    "                    #print(type(dt_train_bucket))\n",
    "                    #print(type(train_y))\n",
    "                    pipeline.fit(dt_train_bucket, train_y)\n",
    "\n",
    "                    if cls_method == \"svm\":\n",
    "                        preds = pipeline.decision_function(dt_test_bucket)\n",
    "                    else:\n",
    "                        preds_pos_label_idx = np.where(cls.classes_ == 1)[0][0]\n",
    "                        preds = pipeline.predict_proba(dt_test_bucket)[:,preds_pos_label_idx]\n",
    "            \n",
    "            if \"prefix\" in method_name:\n",
    "                auc = 0.5\n",
    "                if len(set(test_y)) == 2: \n",
    "                    auc = roc_auc_score(test_y, preds)\n",
    "                scores[bucket] += auc\n",
    "            preds_all.extend(preds)\n",
    "            test_y_all.extend(test_y)\n",
    "\n",
    "        score += roc_auc_score(test_y_all, preds_all)\n",
    "    \n",
    "    if \"prefix\" in method_name:\n",
    "        for k, v in args.items():\n",
    "            for bucket, bucket_score in scores.items():\n",
    "                fout_all.write(\"%s;%s;%s;%s;%s;%s;%s;%s\\n\" % (trial_nr, dataset_name, cls_method, method_name, bucket, k, v, bucket_score / n_splits))   \n",
    "        fout_all.write(\"%s;%s;%s;%s;%s;%s;%s;%s\\n\" % (trial_nr, dataset_name, cls_method, method_name, 0, \"processing_time\", time.time() - start, 0))  \n",
    "    else:\n",
    "        for k, v in args.items():\n",
    "            fout_all.write(\"%s;%s;%s;%s;%s;%s;%s\\n\" % (trial_nr, dataset_name, cls_method, method_name, k, v, score / n_splits))   \n",
    "        fout_all.write(\"%s;%s;%s;%s;%s;%s;%s\\n\" % (trial_nr, dataset_name, cls_method, method_name, \"processing_time\", time.time() - start, 0))   \n",
    "    fout_all.flush()\n",
    "    return {'loss': -score / n_splits, 'status': STATUS_OK, 'model': cls}\n",
    "\n",
    "\n",
    "# dataset_ref = argv[1]\n",
    "# params_dir = argv[2]\n",
    "# n_iter = int(argv[3])\n",
    "# bucket_method = argv[4]\n",
    "# cls_encoding = argv[5]\n",
    "# cls_method = argv[6]\n",
    "\n",
    "dataset_ref = \"bpic2012\"\n",
    "params_dir = \"params\"\n",
    "n_iter = 3\n",
    "bucket_method = \"single\"\n",
    "cls_encoding = \"agg\"\n",
    "cls_method = \"cb\"\n",
    "\n",
    "if bucket_method == \"state\":\n",
    "    bucket_encoding = \"last\"\n",
    "else:\n",
    "    bucket_encoding = \"agg\"\n",
    "\n",
    "method_name = \"%s_%s\"%(bucket_method, cls_encoding)\n",
    "\n",
    "dataset_ref_to_datasets = {\n",
    "    \"bpic2011\": [\"bpic2011_f%s\"%formula for formula in range(1,5)],\n",
    "    \"bpic2015\": [\"bpic2015_%s_f2\"%(municipality) for municipality in range(5,6)],\n",
    "    \"insurance\": [\"insurance_activity\", \"insurance_followup\"],\n",
    "    \"bpic2012\" : [\"bpic2012_accepted\"],\n",
    "    \"sepsis_cases\": [\"sepsis_cases_1\", \"sepsis_cases_2\", \"sepsis_cases_4\"]\n",
    "}\n",
    "\n",
    "encoding_dict = {\n",
    "    \"laststate\": [\"static\", \"last\"],\n",
    "    \"agg\": [\"static\", \"agg\"],\n",
    "    \"index\": [\"static\", \"index\"],\n",
    "    \"combined\": [\"static\", \"last\", \"agg\"]\n",
    "}\n",
    "\n",
    "datasets = [dataset_ref] if dataset_ref not in dataset_ref_to_datasets else dataset_ref_to_datasets[dataset_ref]\n",
    "methods = encoding_dict[cls_encoding]\n",
    "print(datasets)\n",
    "    \n",
    "train_ratio = 0.8\n",
    "n_splits = 3\n",
    "random_state = 22\n",
    "\n",
    "# create results directory\n",
    "if not os.path.exists(os.path.join(params_dir)):\n",
    "    os.makedirs(os.path.join(params_dir))\n",
    "    \n",
    "for dataset_name in datasets:\n",
    "    \n",
    "    # read the data\n",
    "    dataset_manager = DatasetManager(dataset_name)\n",
    "    data = dataset_manager.read_dataset()\n",
    "    cls_encoder_args = {'case_id_col': dataset_manager.case_id_col, \n",
    "                        'static_cat_cols': dataset_manager.static_cat_cols,\n",
    "                        'static_num_cols': dataset_manager.static_num_cols, \n",
    "                        'dynamic_cat_cols': dataset_manager.dynamic_cat_cols,\n",
    "                        'dynamic_num_cols': dataset_manager.dynamic_num_cols, \n",
    "                        'fillna': True}\n",
    "\n",
    "    # determine min and max (truncated) prefix lengths\n",
    "    min_prefix_length = 1\n",
    "    if \"traffic_fines\" in dataset_name:\n",
    "        max_prefix_length = 10\n",
    "    elif \"bpic2017\" in dataset_name:\n",
    "        max_prefix_length = min(20, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n",
    "    else:\n",
    "        max_prefix_length = min(40, dataset_manager.get_pos_case_length_quantile(data, 0.90))\n",
    "\n",
    "    # split into training and test\n",
    "    print(\"splitting data\")\n",
    "    train, _ = dataset_manager.split_data_strict(data, train_ratio, split=\"temporal\")\n",
    "    \n",
    "    # prepare chunks for CV\n",
    "    dt_prefixes = []\n",
    "    class_ratios = []\n",
    "    for train_chunk, test_chunk in dataset_manager.get_stratified_split_generator(train, n_splits=n_splits):\n",
    "        class_ratios.append(dataset_manager.get_class_ratio(train_chunk))\n",
    "        # generate data where each prefix is a separate instance\n",
    "        dt_prefixes.append(dataset_manager.generate_prefix_data(test_chunk, min_prefix_length, max_prefix_length))\n",
    "    del train\n",
    "        \n",
    "    # set up search space\n",
    "    if cls_method == \"rf\":\n",
    "        space = {'max_features': hp.uniform('max_features', 0, 1)}\n",
    "    elif cls_method == \"xgboost\":\n",
    "        space = {'learning_rate': hp.uniform(\"learning_rate\", 0, 1),\n",
    "                 'subsample': hp.uniform(\"subsample\", 0.5, 1),\n",
    "                 'max_depth': scope.int(hp.quniform('max_depth', 4, 30, 1)),\n",
    "                 'colsample_bytree': hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "                 'min_child_weight': scope.int(hp.quniform('min_child_weight', 1, 6, 1))}\n",
    "    elif cls_method == \"logit\":\n",
    "        space = {'C': hp.uniform('C', -15, 15)}\n",
    "    elif cls_method == \"svm\":\n",
    "        space = {'C': hp.uniform('C', -15, 15),\n",
    "                 'gamma': hp.uniform('gamma', -15, 15)}\n",
    "    elif cls_method == \"cb\":\n",
    "        space = {'learning_rate': hp.uniform(\"learning_rate\", 0, 1),\n",
    "                 'depth': scope.int(hp.quniform('max_depth', 4, 30, 1)),\n",
    "                 'subsample': hp.uniform(\"subsample\", 0.5, 1)}\n",
    "    if bucket_method == \"cluster\":\n",
    "        space['n_clusters'] = scope.int(hp.quniform('n_clusters', 2, 50, 1))\n",
    "\n",
    "    # optimize parameters\n",
    "    trial_nr = 1\n",
    "    trials = Trials()\n",
    "    fout_all = open(os.path.join(params_dir, \"param_optim_all_trials_%s_%s_%s.csv\" % (cls_method, dataset_name, method_name)), \"w\")\n",
    "    if \"prefix\" in method_name:\n",
    "        fout_all.write(\"%s;%s;%s;%s;%s;%s;%s;%s\\n\" % (\"iter\", \"dataset\", \"cls\", \"method\", \"nr_events\", \"param\", \"value\", \"score\"))   \n",
    "    else:\n",
    "        fout_all.write(\"%s;%s;%s;%s;%s;%s;%s\\n\" % (\"iter\", \"dataset\", \"cls\", \"method\", \"param\", \"value\", \"score\"))   \n",
    "    best = fmin(create_and_evaluate_model, space, algo=tpe.suggest, max_evals=n_iter, trials=trials, verbose=True)\n",
    "    fout_all.close()\n",
    "\n",
    "    # write the best parameters\n",
    "    best_params = hyperopt.space_eval(space, best)\n",
    "    outfile = os.path.join(params_dir, \"optimal_params_%s_%s_%s.pickle\" % (cls_method, dataset_name, method_name))\n",
    "    # write to file\n",
    "    with open(outfile, \"wb\") as fout:\n",
    "        pickle.dump(best_params, fout)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
